{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing\n",
    "\n",
    "- Subset dataset to movies/users appearing at least n/m times\n",
    "- compactify movie ids\n",
    "- do train/test split?\n",
    "\n",
    "Output = new versions of...\n",
    "\n",
    "rating.csv. As before except\n",
    "- no timestamp column\n",
    "- use compactified movieIds\n",
    "- add val/train flag\n",
    "- add 'y' col (centred)\n",
    "- add 'yscaled' col\n",
    "\n",
    "movie.csv. As before except\n",
    "- new compactified movieIds\n",
    "- parse out base title and year into separate cols (keeping original as well - maybe as 'key' column)\n",
    "- nratings col\n",
    "- avg_rating col\n",
    "\n",
    "Also, some other file mapping between old and new movie ids (just in case that's useful later?)\n",
    "Or maybe just store in movie.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from functools import lru_cache\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import sklearn.preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack for running on kernels and locally\n",
    "RUNNING_ON_KERNELS = 'KAGGLE_WORKING_DIR' in os.environ\n",
    "input_dir = '../input' if RUNNING_ON_KERNELS else '../input/movies'\n",
    "out_dir = '.' if RUNNING_ON_KERNELS else '../input/movielens_preprocessed'\n",
    "\n",
    "rating_path = os.path.join(input_dir, 'rating.csv')\n",
    "df = pd.read_csv(rating_path, usecols=['userId', 'movieId', 'rating'])\n",
    "# Shuffle (reproducibly)\n",
    "df = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "# Partitioning train/val according to behaviour of keras.Model.fit() when called with\n",
    "# validation_split kwarg (which is to take validation data from the end as a contiguous\n",
    "# chunk)\n",
    "val_split = .05\n",
    "n_ratings = len(df)\n",
    "n_train = math.floor(n_ratings * (1-val_split))\n",
    "itrain = df.index[:n_train]\n",
    "ival = df.index[n_train:]\n",
    "\n",
    "# Compactify movie ids. \n",
    "movie_id_encoder = LabelEncoder()\n",
    "# XXX: Just fitting globally for simplicity. See movie_helpers.py for more 'principled'\n",
    "# approach. I don't think there's any realistically useful data leakage here though.\n",
    "#orig_movieIds = df['movieId']\n",
    "df['movieId'] = movie_id_encoder.fit_transform(df['movieId'])\n",
    "\n",
    "# Add centred target variable\n",
    "df['y'] = df['rating'] - df.loc[itrain, 'rating'].mean()\n",
    "\n",
    "SCALE = 0\n",
    "if SCALE:\n",
    "    # Add version of target variable scale to [0, 1]\n",
    "    yscaler = sklearn.preprocessing.MinMaxScaler()\n",
    "    yscaler.fit(df.loc[itrain, 'rating'].values.reshape(-1, 1))\n",
    "    df['y_unit_scaled'] = yscaler.transform(df['rating'].values.reshape(-1, 1))\n",
    "\n",
    "path = os.path.join(out_dir, 'rating.csv')\n",
    "df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a 10% sample of ratings for exercises (with re-compactified movieIds, and mapping back to canonical movie ids)\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "movie_counts = df.groupby('movieId').size()\n",
    "thresh = 1000\n",
    "pop_movies = movie_counts[movie_counts >= thresh].index\n",
    "\n",
    "pop_df = df[df.movieId.isin(pop_movies)]\n",
    "\n",
    "# Take approx 10% of the whole dataset\n",
    "frac = 2 * 10**6 / len(pop_df)\n",
    "print(frac)\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=frac, random_state=1)\n",
    "splits = splitter.split(pop_df, groups=pop_df.userId)\n",
    "_, mini = next(splits)\n",
    "\n",
    "mini_df = pop_df.iloc[mini].copy()\n",
    "\n",
    "print(\n",
    "    '{:,}'.format(len(mini_df)),\n",
    "    len(df.userId.unique()) // 1000,\n",
    "    len(mini_df.userId.unique()) // 1000,\n",
    "    sep='\\n',\n",
    ")\n",
    "\n",
    "# Compactify ids\n",
    "\n",
    "def compactify_ids(df, col, backup=True):\n",
    "    encoder = LabelEncoder()\n",
    "    if backup:\n",
    "        df[col+'_orig'] = df[col]\n",
    "    df[col] = encoder.fit_transform(df[col])\n",
    "    \n",
    "for col in ['movieId', 'userId']:\n",
    "    compactify_ids(mini_df, col, backup=col=='movieId')\n",
    "    \n",
    "# Shuffle\n",
    "mini_df = mini_df.sample(frac=1, random_state=1)\n",
    "\n",
    "# Recalculate y (just to be totally on the level. Very little opportunity for contamination here.)\n",
    "val_split = .05\n",
    "n_mini_train = math.floor(len(mini_df) * (1-val_split))\n",
    "mini_train_rating_mean = mini_df.iloc[:n_mini_train]['rating'].mean()\n",
    "mini_df['y'] = mini_df['rating'] - mini_train_rating_mean\n",
    "\n",
    "path = os.path.join(out_dir, 'mini_rating.csv')\n",
    "mini_df.to_csv(path, index=False)\n",
    "\n",
    "print(\n",
    "    df.userId.max(),\n",
    "    mini_df.userId.max(),\n",
    "    '\\n',\n",
    "    df.movieId.max(),\n",
    "    mini_df.movieId.max(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def munge_title(title):\n",
    "    i = title.rfind(' (')\n",
    "    if i != -1:\n",
    "        title = title[:i]\n",
    "    for suff_word in ['The', 'A', 'An']:\n",
    "        suffix = ', {}'.format(suff_word)\n",
    "        if title.endswith(suffix):\n",
    "            title = suff_word + ' ' + title[:-len(suffix)]\n",
    "    return title\n",
    "\n",
    "def get_year(title):\n",
    "    l = title.rfind('(') + 1\n",
    "    try:\n",
    "        return int(title[l:l+4])\n",
    "    except ValueError:\n",
    "        print(title, end='\\t')\n",
    "        return 0\n",
    "\n",
    "movie_path = os.path.join(input_dir, 'movie.csv')\n",
    "movie_df = pd.read_csv(movie_path)\n",
    "mdf = movie_df\n",
    "\n",
    "# XXX: hack\n",
    "assert mdf.loc[\n",
    "    mdf.movieId==64997,\n",
    "    'title'].iloc[0] == 'War of the Worlds (2005)'\n",
    "mdf.loc[\n",
    "    mdf.movieId==64997,\n",
    "    'title'\n",
    "] = 'War of the Worlds (2005)x'\n",
    "\n",
    "#mdf['movieId_orig'] = mdf['movieId']\n",
    "n_orig = len(mdf)\n",
    "\n",
    "# There are some movies listed in movie.csv which have no ratings. Drop them.\n",
    "whitelist = set(movie_id_encoder.classes_)\n",
    "mdf = mdf[mdf['movieId'].isin(whitelist)].copy()\n",
    "print(\"Went from {} movies to {} after filtering out movies with no ratings\".format(\n",
    "    n_orig, len(mdf)\n",
    "))\n",
    "\n",
    "# New, compact movie Ids\n",
    "mdf['movieId'] = movie_id_encoder.transform(mdf['movieId'].values)\n",
    "\n",
    "mdf = mdf.sort_values(by='movieId').reset_index(drop=True)\n",
    "\n",
    "# By default use original title field (which includes year of release) as unique key\n",
    "mdf['key'] = mdf['title']\n",
    "\n",
    "mdf['year'] = mdf['title'].map(get_year)\n",
    "mdf['title'] = mdf['title'].map(munge_title)\n",
    "\n",
    "# For movies whose munged title are unique, use it as their key\n",
    "title_counts = mdf.groupby('title').size()\n",
    "unique_titles = title_counts.index[title_counts == 1]\n",
    "unique_ids = mdf.index[mdf.title.isin(unique_titles)]\n",
    "mdf.loc[unique_ids, 'key'] = mdf.loc[unique_ids, 'title']\n",
    "\n",
    "mdf['n_ratings'] = df.groupby('movieId').size()\n",
    "mean_ratings = df.groupby('movieId')['rating'].mean()\n",
    "mdf['mean_rating'] = mean_ratings\n",
    "\n",
    "path = os.path.join(out_dir, 'movie.csv')\n",
    "mdf.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "learntools_metadata": {
   "lesson_index": -1,
   "type": "tutorial"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

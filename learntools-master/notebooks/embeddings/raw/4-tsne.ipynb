{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous lesson, we looked at some examples of the movie embeddings we learned, measured the distances between pairs of movies, looked up movies most similar to certain movies, and had some fun composing the semantics of movies with vector math. These are great ways to debug an embedding model, or understand how it works. But it's also pretty time-consuming.\n",
    "\n",
    "In this lesson you'll learn how to use the t-SNE algorithm to visualize embeddings. This is a nice cheap technique for understanding the nature of your embeddings.\n",
    "\n",
    "# t-SNE?\n",
    "\n",
    "Visualizing data in 1 or 2 dimensions is easy - but it's not clear how to visualize embeddings which are 8-dimensional or 32-dimensional. t-SNE is a **dimensionality reduction** algorithm which is often used for visualization. It learns a mapping from a set of high-dimensional vectors, to a space with a smaller number of dimensions (usually 2), which is hopefully a good representation of the high-dimensional space.\n",
    "\n",
    "What makes a mapping a \"good representation\"? Put simply, t-SNE tries to make sure that if high-dimensional vectors $\\mathbf{u}$ and $\\mathbf{v}$ are close together, then $map(\\mathbf{u})$ and $map(\\mathbf{v})$ are close together in the 2-d mapping space.\n",
    "\n",
    "# The code\n",
    "\n",
    "To start, we'll load our pretrained embeddings, like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$HIDE$\n",
    "%matplotlib inline\n",
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "#_RM_\n",
    "input_dir = '../input/movielens_preprocessed'\n",
    "#_UNCOMMENT_\n",
    "#input_dir = '../input/movielens-preprocessing'\n",
    "#_RM_\n",
    "model_dir = '.'\n",
    "#_UNCOMMENT_\n",
    "#model_dir = '../input/movielens-spiffy-model'\n",
    "model_path = os.path.join(model_dir, 'movie_svd_model_32.h5')\n",
    "\n",
    "model = keras.models.load_model(model_path)\n",
    "emb_layer = model.get_layer('movie_embedding')\n",
    "(w,) = emb_layer.get_weights()\n",
    "\n",
    "movies_path = os.path.join(input_dir, 'movie.csv')\n",
    "movies_df = pd.read_csv(movies_path, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in our earlier lesson, our dataset has lots of obscure movies with few ratings (sometimes as few as one). We know so little about these movies that their embeddings are as good as random. We can clarify our visualization by selecting only movies that meet some popularity threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 100\n",
    "mainstream_movies = movies_df[movies_df.n_ratings >= threshold].reset_index(drop=True)\n",
    "print(\"Went from {} to {} movies after applying threshold\".format(\n",
    "    len(movies_df), len(mainstream_movies),\n",
    "))\n",
    "w_full = w\n",
    "w = w[mainstream_movies.movieId]\n",
    "df = mainstream_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using [scikit-learn's t-SNE implementation](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html).\n",
    "\n",
    "I mentioned that t-SNE tries to preserve \"closeness\" between entities in the feature space. As we saw in the previous lessons, there are a lot of competing notions of distance. By default, t-SNE uses euclidean distance. But because cosine distance is known to work well on embeddings, we'll pass in `metric=\"cosine\"` when creating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM%%\n",
    "# Note: the cell below takes ages. For quick local development, do the following instead:\n",
    "df = pd.read_csv('movies_tsne.csv', index_col=0)\n",
    "embs = df[ ['x', 'y'] ].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# The default of 1,000 iterations gives fine results, but I'm training for longer just to eke\n",
    "# out some marginal improvements. NB: This takes almost an hour!\n",
    "tsne = TSNE(random_state=1, n_iter=15000, metric=\"cosine\")\n",
    "\n",
    "embs = tsne.fit_transform(w)\n",
    "# Add to dataframe for convenience\n",
    "df['x'] = embs[:, 0]\n",
    "df['y'] = embs[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$HIDE_INPUT$\n",
    "# Save a copy of our t-SNE mapping data for later use (we'll be loading this file in the exercise)\n",
    "#_UNCOMMENT_\n",
    "#df.to_csv('movies_tsne.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a sample of the 2-d vectors we've mapped our movies to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole point of doing this dimensionality reduction was visualization, so let's use matplotlib to draw a scatter plot of our movies, using our new 2-d mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = (10, 8)\n",
    "fig, ax = plt.subplots(figsize=FS)\n",
    "# Make points translucent so we can visually identify regions with a high density of overlapping points\n",
    "ax.scatter(df.x, df.y, alpha=.1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Did it work? \n",
    "\n",
    "It's hard to judge by the shape alone. A good sanity check is to identify some groups of movies that we strongly believe *should* be close together, and see whether they're close in the 2-d space.\n",
    "\n",
    "For example, all the Harry Potter movies should be close together, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$HIDE_INPUT$\n",
    "# Some helper functions for plotting annotated t-SNE visualizations\n",
    "\n",
    "# TODO: adjust_text not available in kernels\n",
    "try:\n",
    "    from adjustText import adjust_text\n",
    "except ImportError:\n",
    "    def adjust_text(*args, **kwargs):\n",
    "        pass\n",
    "\n",
    "def adjust_text(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "def plot_bg(bg_alpha=.01, figsize=(13, 9), emb_2d=None):\n",
    "    \"\"\"Create and return a plot of all our movie embeddings with very low opacity.\n",
    "    (Intended to be used as a basis for further - more prominent - plotting of a \n",
    "    subset of movies. Having the overall shape of the map space in the background is\n",
    "    useful for context.)\n",
    "    \"\"\"\n",
    "    if emb_2d is None:\n",
    "        emb_2d = embs\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    X = emb_2d[:, 0]\n",
    "    Y = emb_2d[:, 1]\n",
    "    ax.scatter(X, Y, alpha=bg_alpha)\n",
    "    return ax\n",
    "\n",
    "def annotate_sample(n, n_ratings_thresh=0):\n",
    "    \"\"\"Plot our embeddings with a random sample of n movies annotated.\n",
    "    Only selects movies where the number of ratings is at least n_ratings_thresh.\n",
    "    \"\"\"\n",
    "    sample = mainstream_movies[mainstream_movies.n_ratings >= n_ratings_thresh].sample(\n",
    "        n, random_state=1)\n",
    "    plot_with_annotations(sample.index)\n",
    "\n",
    "def plot_by_title_pattern(pattern, **kwargs):\n",
    "    \"\"\"Plot all movies whose titles match the given regex pattern.\n",
    "    \"\"\"\n",
    "    match = df[df.title.str.contains(pattern)]\n",
    "    return plot_with_annotations(match.index, **kwargs)\n",
    "\n",
    "def add_annotations(ax, label_indices, emb_2d=None, **kwargs):\n",
    "    if emb_2d is None:\n",
    "        emb_2d = embs\n",
    "    X = emb_2d[label_indices, 0]\n",
    "    Y = emb_2d[label_indices, 1]\n",
    "    ax.scatter(X, Y, **kwargs)\n",
    "\n",
    "def plot_with_annotations(label_indices, text=True, labels=None, alpha=1, **kwargs):\n",
    "    ax = plot_bg(**kwargs)\n",
    "    Xlabeled = embs[label_indices, 0]\n",
    "    Ylabeled = embs[label_indices, 1]\n",
    "    if labels is not None:\n",
    "        for x, y, label in zip(Xlabeled, Ylabeled, labels):\n",
    "            ax.scatter(x, y, alpha=alpha, label=label, marker='1',\n",
    "                       s=90,\n",
    "                      )\n",
    "        fig.legend()\n",
    "    else:\n",
    "        ax.scatter(Xlabeled, Ylabeled, alpha=alpha, color='green')\n",
    "    \n",
    "    if text:\n",
    "        # TODO: Add abbreviated title column\n",
    "        titles = mainstream_movies.loc[label_indices, 'title'].values\n",
    "        texts = []\n",
    "        for label, x, y in zip(titles, Xlabeled, Ylabeled):\n",
    "            t = ax.annotate(label, xy=(x, y))\n",
    "            texts.append(t)\n",
    "        adjust_text(texts, \n",
    "                    #expand_text=(1.01, 1.05),\n",
    "                    arrowprops=dict(arrowstyle='->', color='red'),\n",
    "                   )\n",
    "    return ax\n",
    "\n",
    "FS = (13, 9)\n",
    "def plot_region(x0, x1, y0, y1, text=True):\n",
    "    \"\"\"Plot the region of the mapping space bounded by the given x and y limits.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=FS)\n",
    "    pts = df[\n",
    "        (df.x >= x0) & (df.x <= x1)\n",
    "        & (df.y >= y0) & (df.y <= y1)\n",
    "    ]\n",
    "    ax.scatter(pts.x, pts.y, alpha=.6)\n",
    "    ax.set_xlim(x0, x1)\n",
    "    ax.set_ylim(y0, y1)\n",
    "    if text:\n",
    "        texts = []\n",
    "        for label, x, y in zip(pts.title.values, pts.x.values, pts.y.values):\n",
    "            t = ax.annotate(label, xy=(x, y))\n",
    "            texts.append(t)\n",
    "        adjust_text(texts, expand_text=(1.01, 1.05))\n",
    "    return ax\n",
    "\n",
    "def plot_region_around(title, margin=5, **kwargs):\n",
    "    \"\"\"Plot the region of the mapping space in the neighbourhood of the the movie with\n",
    "    the given title. The margin parameter controls the size of the neighbourhood around\n",
    "    the movie.\n",
    "    \"\"\"\n",
    "    xmargin = ymargin = margin\n",
    "    match = df[df.title == title]\n",
    "    assert len(match) == 1\n",
    "    row = match.iloc[0]\n",
    "    return plot_region(row.x-xmargin, row.x+xmargin, row.y-ymargin, row.y+ymargin, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This and several other helper functions are defined in a code cell above. Hit the \"code\"\n",
    "# button above if you're curious about how they're implemented.\n",
    "plot_by_title_pattern('Harry Potter', figsize=(15, 9), bg_alpha=.05, text=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above has a green dot for each of the 8 Harry Potter movies - but they're so close together, they're impossible to distinguish at this scale. That's a good sign!\n",
    "\n",
    "Let's zoom in to get a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_region_around('Harry Potter and the Order of the Phoenix', 4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only are the Harry Potter movies tightly clustered, they're arranged roughly in order of release!\n",
    "\n",
    "<!-- TODO. Lest you think we just got lucky this time, feel free to click the \"output\" button on any of the below cells to see some more examples of how our mapping places movies from other franchises. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local vs. Global structure\n",
    "\n",
    "One of the key features of t-SNE which makes it so good for visualization is that it's good at capturing clusters *at multiple scales*. We've seen that our mapping is successfully capturing small, tight, local structures. What about bigger structures encompassing more loosely related movies?\n",
    "\n",
    "We've already seen a small example of this above: the closest neighbours to the Harry Potter movies are movies from the *Hunger Games* series - another set of movies based on a series of young adult fantasy books. Makes sense!\n",
    "\n",
    "What about less niche genres? Where do documentaries fall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df[ (df.genres == 'Documentary') ]\n",
    "plot_with_annotations(docs.index, text=False, alpha=.4, figsize=(15, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! It's not a tight cluster, but there's definitely a strong pattern here.\n",
    "\n",
    "And just to reiterate: we never actually showed the model genre as a feature. It can't read the titles to see that *Harry Potter and the Philosopher's Stone* and *Harry Potter and the Chamber of Secrets* belong to the same series. It managed to pick up these latent patterns and incorporate them into the embedding space just by seeing data points like \"user 5299 gave movie 806 a rating of 4.5\". Pretty impressive!\n",
    "\n",
    "Here's another, slightly more complicated genre experiment: visualizing all movies whose genres are a subset of `{Comedy, Drama, Romance}` (i.e. comedies, dramas, romances, dramedies, romantic dramas, romcoms, and... \"dromcoms\" I guess?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$HIDE_INPUT$\n",
    "import itertools\n",
    "sample_rate = 1\n",
    "genre_components = ['Comedy', 'Drama', 'Romance']\n",
    "genre_combos = set()\n",
    "for size in range(1, 4):\n",
    "    combo_strs = ['|'.join(genres) for genres in itertools.combinations(genre_components, size)]\n",
    "    genre_combos.update(combo_strs)\n",
    "\n",
    "ax = plot_bg(figsize=(16, 10))\n",
    "dromcoms = df[df.genres.isin(genre_combos)]\n",
    "if sample_rate != 1:\n",
    "    dromcoms = dromcoms.sample(frac=sample_rate, random_state=1)\n",
    "for i, genre in enumerate(genre_components):\n",
    "    m = dromcoms[dromcoms.genres.str.contains(genre)]\n",
    "    marker = str(i+1)\n",
    "    add_annotations(ax, m.index, label=genre, alpha=.5, marker=marker, s=150, linewidths=5)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an awesome example of structure at the largest scale. Dramas are mostly in the upper-right half, and comedies are mostly in the other half (with romances having a more spread-out, bursty distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#$YOURTURN$\n",
    "#$TUT_BETA_NOTE(82826376784270)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Reading\n",
    "\n",
    "We achieved good results using the default out-of-the box parameters for our t-SNE model, but depending on the characteristics of your data, you may not be so lucky.\n",
    "\n",
    "t-SNE isn't a simple closed-form mathematical operation. You're training a model to minimize some non-convex loss function using stochastic gradient descent. It may take a while, and require a bit of fiddling. You may even see very different results between two t-SNE models trained with the same parameters (set a fixed `random_state` if you want reproducibility).\n",
    "\n",
    "The links below have some information you may find helpful if you're getting unsatisfactory results when trying to train a t-SNE model - or if you're just interested in learning more the underlying mathematics and implementation.\n",
    "\n",
    "- If you're interested in more in-depth, mathematical detail on t-SNE, I highly recommend checking out [the original paper by Laurens van der Maaten and Geoff Hinton that introduced t-SNE to the world](http://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf).\n",
    "- [How to Use t-SNE effectively](https://distill.pub/2016/misread-tsne/) features some incredible live, interactive examples, allowing you to apply t-SNE to various synthetic datasets and watch the training happen in real-time, and see the effect of changing parameters like the perplexity.\n",
    "- The [sklearn TSNE docs](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) have good information on the meaning of each parameter, and some tips for setting them.\n",
    "    - See also: [scikit-learn's t-SNE user guide](http://scikit-learn.org/stable/modules/manifold.html#t-sne)\n",
    "- [t-SNE FAQ](https://lvdmaaten.github.io/tsne/#faq) written by Laurens van der Maaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_BELOW%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`</tutorial>`\n",
    "\n",
    "# Scratch space below - please ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_counts = df.groupby('genres').size()\n",
    "horror_genres = genre_counts[\n",
    "    (genre_counts >= 45) & (genre_counts.index.str.contains('Horror'))\n",
    "].index\n",
    "sub = df[df.genres.isin(horror_genres)]\n",
    "g = sub.groupby('genres')\n",
    "\n",
    "ax = plot_bg(figsize=(16, 9), bg_alpha=.006)\n",
    "\n",
    "for genre, group in g:\n",
    "    add_annotations(ax, group.index, label=genre, alpha=.25)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dromcoms 2\n",
    "import itertools\n",
    "genre_components = ['Comedy', 'Drama', 'Romance']\n",
    "genre_combos = set()\n",
    "for size in range(1, 4):\n",
    "    combo_strs = ['|'.join(genres) for genres in itertools.combinations(genre_components, size)]\n",
    "    genre_combos.update(combo_strs)\n",
    "\n",
    "ax = plot_bg(figsize=(16, 16))\n",
    "dromcoms = df[df.genres.isin(genre_combos)]\n",
    "g = dromcoms.groupby('genres')\n",
    "for genre, group in g:\n",
    "    add_annotations(ax, group.index, label=genre, alpha=.25)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes/scratch\n",
    "\n",
    "tips:\n",
    "- monitor training by setting verbose=1\n",
    "- experiment with params. \n",
    "- train on all data\n",
    "- distance metric?\n",
    "\n",
    "- TODO: maybe try running on another dataset as well? Wouldn't be so hard. Probably.\n",
    "\n",
    "- would be cool to color by genre, or by...\n",
    "    - avg. rating\n",
    "    - MPAA rating\n",
    "    - year\n",
    "- plot many/all points, and add labels for just a certain subset at a time. e.g. Adam Sandler movies. Best Picture winners. etc.\n",
    "- try generating a few maps with the same params (but no fixed seed). See how much variation exists between them.\n",
    "\n",
    "question: train on all datapoints, then sample the ones to visualize? Or only train on the subset you're planning on visualizing?\n",
    "\n",
    "Relevant quote:\n",
    "\n",
    "> Obviously, it is possible to\n",
    "pick a random subset of the datapoints and display them using t-SNE, but such an approach fails to \n",
    "make use of the information that the undisplayed datapoints provide about the underlying manifolds.\n",
    "Suppose, for example, that A, B, and C are all equidistant in the high-dimensional space. If there\n",
    "are many undisplayed datapoints between A and B and none between A and C, it is much more\n",
    "likely that A and B are part of the same cluster than A and C. \n",
    "\n",
    "further reading: http://jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf (how it works, why it's useful specifically for viz, how it's different from stuff like PCA)\n",
    "\n",
    "sklearn t-sne user guide looks like a good resource: http://scikit-learn.org/stable/modules/manifold.html#t-sne\n",
    "\n",
    "goals: https://distill.pub/2016/misread-tsne/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "learntools_metadata": {
   "lesson_index": 3,
   "type": "tutorial"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise (Gensim / vector math)\n",
    "\n",
    "In this exercise, you'll get to do some of your exploration of our trained movie embeddings, using some of the Gensim tools I showed in [the tutorial](#$TUTORIAL_URL(3)$). To get started, run the setup cell below to import the libraries we'll be using, load our raw embedding data, and wrap it in a `WordEmbeddingsKeyedVectors` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from gensim.models.keyedvectors import WordEmbeddingsKeyedVectors\n",
    "\n",
    "from learntools.core import binder; binder.bind(globals())\n",
    "from learntools.embeddings.ex3_gensim import *\n",
    "\n",
    "#_RM_\n",
    "input_dir = '../input/movielens_preprocessed'\n",
    "#_UNCOMMENT_\n",
    "#input_dir = '../input/movielens-preprocessing'\n",
    "#_RM_\n",
    "model_dir = '.'\n",
    "#_UNCOMMENT_\n",
    "#model_dir = '../input/movielens-spiffy-model'\n",
    "model_path = os.path.join(model_dir, 'movie_svd_model_32.h5')\n",
    "model = keras.models.load_model(model_path)\n",
    "\n",
    "emb_layer = model.get_layer('movie_embedding')\n",
    "(w,) = emb_layer.get_weights()\n",
    "movie_embedding_size = w.shape[1]\n",
    "\n",
    "movies_path = os.path.join(input_dir, 'movie.csv')\n",
    "all_movies_df = pd.read_csv(movies_path, index_col=0)\n",
    "\n",
    "threshold = 100\n",
    "\n",
    "movies = all_movies_df[all_movies_df.n_ratings >= threshold].reset_index(drop=True)\n",
    "\n",
    "kv = WordEmbeddingsKeyedVectors(movie_embedding_size)\n",
    "kv.add(\n",
    "    movies['key'].values,\n",
    "    w[movies.movieId]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Warm-up\n",
    "\n",
    "As a warm-up, try using the `kv.most_similar` method on a few of your favourite movies. What do you think of the results? Are there any that stick out as being a bad match? Any movies that you think *should* be on the list but which aren't? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: one of my favourite films by Alfred Hitchcock. Try with some of your favourite movies.\n",
    "kv.most_similar('Vertigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: if you get a KeyError when looking up a movie, you may want to run something like this\n",
    "# to look up the 'key' column for your movie. For example, there's more than one movie with the \n",
    "# title 'Spellbound', so I need to either call:\n",
    "#     kv.most_similar('Spellbound (1945)')\n",
    "# If I want the Hitchcock thriller, or:\n",
    "#     kv.most_similar('Spellbound (2002)')\n",
    "# If I want the documentary on spelling bees.\n",
    "movies[movies.title.str.contains('Spellbound')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you find any particularly interesting or funny examples, feel free to share them on [the forums](https://www.kaggle.com/learn-forum)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. *Bambi* + *The Mummy* = ???\n",
    "\n",
    "So far we've seen the `most_similar()` method called in the following ways:\n",
    "- with a single (positive) example `m1`, giving us the movies most similar to `m1`\n",
    "- with one positive example, `m1`, and one negative example, `m2`. The results seem to roughly correspond to the question \"which movies exemplify the properties that `m1` has and `m2` doesn't?\"\n",
    "- with two positive examples, `m1` and `m2`, and one negative example, `m3`, which answers the analogy \"`m3` is to `m2` as `m1` is to ____\".\n",
    "\n",
    "What do you think will happen (mathematically, and semantically) if we call it with two positive examples, and no negative examples? \n",
    "\n",
    "In the code cell below, try calling `most_similar()` with *Legally Blonde* and *Mission: Impossible* as two positive examples. If you're familiar with the movies, see if you can predict what kinds of movies will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: call most_similar with the movies \"Legally Blonde\" and \"Mission: Impossible\" as positive examples,\n",
    "# and assign the results to the variable legally_impossible\n",
    "legally_impossible = None\n",
    "part2.check()\n",
    "legally_impossible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try experimenting with adding other pairs of movies. Do you see a pattern emerging?\n",
    "\n",
    "What do you think happens if we pass in the same movie twice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to continue experimenting here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the line below to see an explanation of what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_COMMENT_IF(PROD)_\n",
    "part2.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "# Bad solution (wrong call signature)\n",
    "legally_impossible = kv.most_similar(positive=['Legally Blonde'], negative=['Mission: Impossible'])\n",
    "part2.check()\n",
    "legally_impossible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "# Correct (solution code)\n",
    "legally_impossible = kv.most_similar(positive=['Legally Blonde', 'Mission: Impossible'])\n",
    "part2.check()\n",
    "legally_impossible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus**: Pick a movie you like (let's call it `m`), and see if you can find two other movies, `m1` and `m2` such that `m1 + m2 â‰ˆ m`. Of course you're pretty likely to succeed if you choose two movies which are each similar to `m`, but can you come up with a pair of very *different* movies that have `m` right between them? Again, if you're successful here, feel free to share on [the forums](https://www.kaggle.com/learn-forum)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cosine distance vs. Euclidean distance\n",
    "\n",
    "If you're familiar with linear algebra, you may know that the cosine distance and euclidean distance of two vectors are equivalent (up to a scaling factor) if those vectors have the same length. In particular, when our vectors both have length 1, their euclidean distance is just twice their cosine distance.\n",
    "\n",
    "Given that we cared about using cosine distance rather than Euclidean distance, we must have some reason to believe that our embedding vectors vary in length. But how much? And is there any pattern to which movies' vectors are long or short?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Distribution of lengths\n",
    "\n",
    "Just as there are lots of definitions of distance, there are lots of definitions of length. But we'll be using the familiar notion, technically called the 'Euclidean norm' or 'L2 norm'. What's the length of the vector `(3, 4)`? Well, if we start at `(0, 0)`, walk 3 steps to the right, and then 4 steps up, we'll get a right triangle where the hypotenuse connects `(3, 4)` to `(0, 0)`. By the Pythagorean theorem, the length of that hypotenuse is $\\sqrt{3^2 + 4^2} = \\sqrt{25} = 5$. We can extend the calculation to any number of dimensions - for example, the L2 norm of the vector `(1, 1, 3, 5)` is $\\sqrt{1^2 + 1^2 + 3^2 + 5^2} = 6$.\n",
    "\n",
    "Fortunately, we don't need to implement the calculations ourselves. Given a vector, the function [`numpy.linalg.norm`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html) returns its L2 norm. Run the cell below to calculate the L2 norm of our model's first movie embedding vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(w[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the missing code in the cell below to create a variable `norms`, containing the L2 norms of all the model's movie embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = None\n",
    "part3.a.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_COMMENT_IF(PROD)_\n",
    "part3.a.hint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_COMMENT_IF(PROD)_\n",
    "part3.a.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "# Incorrect\n",
    "norms = np.linalg.norm(w)\n",
    "part3.a.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "# Correct (solution code)\n",
    "norms = np.linalg.norm(w, axis=1)\n",
    "part3.a.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've successfully calculated `norms`, run the following cell to generate a visualization of the distribution of lengths of our movie embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_series = pd.Series(norms)\n",
    "ax = norm_series.plot.hist()\n",
    "ax.set_xlabel('Embedding norm');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Patterns in vector lengths?\n",
    "\n",
    "Fill in the missing code below to add a column called `norm` containing the length of each movie's embedding to our DataFrame containing all movies (`all_movies_df`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code goes here. Add the column \"norm\" to our movies dataframe.\n",
    "part3.b.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_COMMENT_IF(PROD)_\n",
    "part3.b.solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "# Silly incorrect soln\n",
    "all_movies_df['norm'] = norms + 1\n",
    "part3.b.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_IF(PROD)%%\n",
    "# Correct (solution code)\n",
    "all_movies_df['norm'] = norms\n",
    "part3.b.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cells below to see the movies with the largest and smallest embedding vectors. Do you see a pattern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "# Movies with the smallest embeddings (as measured by L2 norm)\n",
    "all_movies_df.sort_values(by='norm').head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movies with the largest embeddings\n",
    "all_movies_df.sort_values(by='norm', ascending=False).head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the cell below for some speculation about what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_COMMENT_IF(PROD)_\n",
    "part3.c.solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#$END_OF_EMB_EXERCISE(82826085484264)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%RM_BELOW%%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`</exercise>`\n",
    "\n",
    "# Scratch space\n",
    "\n",
    "## Look up your favourite movie and judge how legit the similar titles are! \n",
    "\n",
    "## multiple positive movies\n",
    "\n",
    "What movies do you get if you combine x + y? What movies lie between x and y?\n",
    "\n",
    "## cos distance vs. euclidean\n",
    "\n",
    "looking at different magnitudes of movies\n",
    "\n",
    "-----------------\n",
    "\n",
    "## analogies? Not sure if better to do in an exercise, or in the body of lesson. Or both.\n",
    "\n",
    "## clustering...?\n",
    "\n",
    "## exploring more gensim methods\n",
    "\n",
    "`doesnt_match`, \n",
    "\n",
    "## Exploring individual dimensions of the embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movies_df[all_movies_df.n_ratings >= threshold].sort_values(by='norm').head(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "learntools_metadata": {
   "lesson_index": 2,
   "type": "exercise"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

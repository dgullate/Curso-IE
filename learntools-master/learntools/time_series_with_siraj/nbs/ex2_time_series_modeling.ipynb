{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Time Series With Siraj Course Home Page](https://kaggle.com/learn/time-series-with-siraj)**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3144c4e3acf6570cccdee57ec7205ad6140814bd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pandas import Series\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c4b3c73366a1fdfde6860bb3cd93ffe65ee6dc25"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/siraj2/Train_SU63ISt.csv\")\n",
    "test = pd.read_csv(\"../input/siraj2/Test_0qrQsBZ.csv\")\n",
    "train_original = train.copy()\n",
    "test_original = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5f90fbfaea3ef1777354018241e084e2a2a957c3"
   },
   "source": [
    "# Extracting Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b04f41f3fd4669ea32f2457a104b09c982cf39a"
   },
   "outputs": [],
   "source": [
    "train['Datetime'] = pd.to_datetime(train.Datetime, format = '%d-%m-%Y %H:%M')\n",
    "test['Datetime'] = pd.to_datetime(test.Datetime, format = '%d-%m-%Y %H:%M')\n",
    "train_original['Datetime'] = pd.to_datetime(train_original.Datetime, format = '%d-%m-%Y %H:%M')\n",
    "test_original['Datetime'] = pd.to_datetime(test_original.Datetime, format = '%d-%m-%Y %H:%M')\n",
    "\n",
    "for i in (train, test, train_original, test_original):\n",
    "    i['year'] = i.Datetime.dt.year\n",
    "    i['month'] = i.Datetime.dt.month\n",
    "    i['day']= i.Datetime.dt.day\n",
    "    i['Hour']=i.Datetime.dt.hour\n",
    "    \n",
    "train['Day of week'] = train['Datetime'].dt.dayofweek\n",
    "temp = train['Datetime']\n",
    "\n",
    "def applyer(row):\n",
    "    if row.dayofweek == 5 or row.dayofweek == 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "temp2 = train['Datetime'].apply(applyer)\n",
    "train['weekend'] = temp2\n",
    "\n",
    "train.index = train['Datetime']\n",
    "df = train.drop('ID',1)\n",
    "ts = df['Count']\n",
    "plt.figure(figsize = (16,8))\n",
    "plt.plot(ts)\n",
    "plt.title(\"Time Series\")\n",
    "plt.xlabel(\"Time (year-month)\")\n",
    "plt.ylabel(\"Passenger Count\")\n",
    "plt.legend(loc = 'best')\n",
    "\n",
    "\n",
    "test.Timestamp = pd.to_datetime(test.Datetime, format='%d-%m-%Y %H:%M')\n",
    "test.index = test.Timestamp\n",
    "\n",
    "#Converting to Daily mean \n",
    "test = test.resample('D').mean()\n",
    "\n",
    "train.Timestamp = pd.to_datetime(train.Datetime, format='%d-%m-%Y %H:%M')\n",
    "train.index = train.Timestamp\n",
    "\n",
    "#Converting to Daily mean\n",
    "train = train.resample('D').mean()\n",
    "\n",
    "Train = train.ix['2012-08-25':'2014-06-24']\n",
    "valid = train.ix['2014-06-25':'2014-09-25']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b83aaa27665d43bf56947c74e02fa618622f4ee5"
   },
   "source": [
    "# Divide data into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8cf94d181df8bc29de7b03d1ee0e12d02f91b384"
   },
   "outputs": [],
   "source": [
    "Train.Count.plot(figsize = (15,8), title = 'Daily Ridership', fontsize = 14, label = 'Train')\n",
    "valid.Count.plot(figsize = (15,8), title = 'Daily Ridership', fontsize =14, label = 'Valid')\n",
    "plt.xlabel('Datetime')\n",
    "plt.ylabel('Passenger Count')\n",
    "plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "96fd3baf36e9c893d4eca4657f12958f4511cbdf"
   },
   "source": [
    "# Predicting Timeseries: Naive Approach\n",
    "\n",
    "In this approach you're simply using the last data point to make a prediction.  Try modifying `y_hat['naive']` and see what happens. You could also try making it more complex or maybe even more Naive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "284e39826fe7da226aadbc4ff974d04bb9533318"
   },
   "outputs": [],
   "source": [
    "dd = np.asarray(Train.Count)\n",
    "y_hat =valid.copy()\n",
    "y_hat['naive']= dd[len(dd)- 1]\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.plot(Train.index, Train['Count'],label = 'Train')\n",
    "plt.plot(valid.index, valid['Count'], label = 'Validation')\n",
    "plt.plot(y_hat.index, y_hat['naive'],  label = 'Naive')\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Naive Forecast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9dd07c502432ca73e0d18d09a497d266a3eb434c"
   },
   "source": [
    "### Calculate the RMSE for a Naive Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a4a0fb6e10e58e4402c466a3d253d44c7da93e4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "rmse = sqrt(mean_squared_error(valid.Count, y_hat.naive))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3a13ba71186bf20d8d619fc028ee0f25213b1034"
   },
   "source": [
    "In this section, try increasgin or decreasing the size of the rolling average widow to see how it affects your Naive predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5a4084d95ec0e5229b43fa0e926ca42dd8b070a5"
   },
   "outputs": [],
   "source": [
    "y_hat_avg = valid.copy()\n",
    "y_hat_avg['moving_average_forecast'] = Train['Count'].rolling(10).mean().iloc[-1]\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.plot(Train['Count'], label = 'Train')\n",
    "plt.plot(valid['Count'], label = 'Validation')\n",
    "plt.plot(y_hat_avg['moving_average_forecast'], label = 'Moving Average Forecast with 10 Observations')\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()\n",
    "\n",
    "y_hat_avg = valid.copy()\n",
    "y_hat_avg['moving_average_forecast'] = Train['Count'].rolling(20).mean().iloc[-1]\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.plot(Train['Count'], label = 'Train')\n",
    "plt.plot(valid['Count'], label = 'Validation')\n",
    "plt.plot(y_hat_avg['moving_average_forecast'],label = 'Moving Average Forecast with 20 Observations')\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()\n",
    "\n",
    "y_hat_avg = valid.copy()\n",
    "y_hat_avg['moving_average_forecast']= Train['Count'].rolling(50).mean().iloc[-1]\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.plot(Train['Count'], label = 'Train')\n",
    "plt.plot(valid['Count'], label = 'Validation')\n",
    "plt.plot(y_hat_avg['moving_average_forecast'], label = \"Moving Average Forecast with 50 Observations\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5a3d08c495e53b2c760a6818c2a8f68c38374063"
   },
   "source": [
    "### Calculate RMSE for a moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "826687f45fe3613552454b8c6fcca0f4f1c800ac"
   },
   "outputs": [],
   "source": [
    "rmse = sqrt(mean_squared_error(valid['Count'], y_hat_avg['moving_average_forecast']))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "55c436a2ff8f8bdc03fcd7a5c9b8c526bb1a2e49"
   },
   "source": [
    "# Predicting Timeseries: Simple Exponential Smoothing\n",
    "\n",
    "Simple Exponential Smoothing is another fun method. Try out different for `smoothing_level` and `optimized`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5802001e255f13be3c84bfac5b289cc4de7f9782"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import ExponentialSmoothing,SimpleExpSmoothing, Holt\n",
    "\n",
    "y_hat = valid.copy()\n",
    "fit2 = SimpleExpSmoothing(np.asarray(Train['Count'])).fit(smoothing_level = 0.6,optimized = False)\n",
    "y_hat['SES'] = fit2.forecast(len(valid))\n",
    "plt.figure(figsize =(15,8))\n",
    "plt.plot(Train['Count'], label = 'Train')\n",
    "plt.plot(valid['Count'], label = 'Validation')\n",
    "plt.plot(y_hat['SES'], label = 'Simple Exponential Smoothing')\n",
    "plt.legend(loc = 'best')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "45214d58cead3a838a629086a2cf4f72d7c330df"
   },
   "source": [
    "### Calculate RMSE for Simple Exponential Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ff18cf53c3ba294219f7ef855b35ac0eac20aa5e"
   },
   "outputs": [],
   "source": [
    "rmse = sqrt(mean_squared_error(valid.Count, y_hat['SES']))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3630634f01b68dcb7bf71f951815f4708057ceae"
   },
   "source": [
    "# Predicting Timeseris: Holt's Linear Trend Model\n",
    "\n",
    "For this method, modify the `smoothing_level` and `smoothing_slope` parameters to see how it affects your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "25b15d3f0471132dfd5d7f1e87f8f47c8f52706c"
   },
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "plt.figure(figsize = (16,8))\n",
    "import statsmodels.api as sm\n",
    "sm.tsa.seasonal_decompose(Train.Count).plot()\n",
    "result = sm.tsa.stattools.adfuller(train.Count)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "511fec7e253db745d083be532e0418435fec0e9d"
   },
   "outputs": [],
   "source": [
    "y_hat_holt = valid.copy()\n",
    "fit1 = Holt(np.asarray(Train['Count'])).fit(smoothing_level = 0.3, smoothing_slope = 0.1)\n",
    "y_hat_holt['Holt_linear'] = fit1.forecast(len(valid))\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.figure(figsize = (15,8))\n",
    "plt.plot(Train.Count, label = 'Train')\n",
    "plt.plot(valid.Count, label = 'Validation')\n",
    "plt.plot(y_hat_holt['Holt_linear'], label = 'Holt Linear')\n",
    "plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e2cfd3bd7a5e2968c2ef1b69bb33e4e0e4d0b2c1"
   },
   "outputs": [],
   "source": [
    "rmse = sqrt(mean_squared_error(valid.Count, y_hat_holt.Holt_linear))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8aa473bc92b6e8d1d4d4d446b4077bfd5a91fccb"
   },
   "outputs": [],
   "source": [
    "predict = fit1.forecast(len(test))\n",
    "test['prediction'] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "61596ea4e2e6cae2ce5ddaac3970abc38404a868"
   },
   "outputs": [],
   "source": [
    "#Calculating hourly ration of count\n",
    "train_original['ratio'] = train_original['Count']/train_original['Count'].sum()\n",
    "\n",
    "#Grouping hourly ratio\n",
    "temp = train_original.groupby(['Hour']) ['ratio'].sum()\n",
    "\n",
    "#Group by to csv format\n",
    "pd.DataFrame(temp, columns= ['Hour', 'ratio']).to_csv('Groupby.csv')\n",
    "temp2 = pd.read_csv(\"Groupby.csv\")\n",
    "temp2 =temp2.drop('Hour.1',1)\n",
    "#Merge test and test_original on day, month and year\n",
    "merge = pd.merge(test, test_original, on = ('day', 'month','year'), how = 'left')\n",
    "merge['Hour'] = merge['Hour_y']\n",
    "merge = merge.drop(['year','month','day','Hour_x','Datetime','Hour_y'], axis =1)\n",
    "\n",
    "#Predicting by merging temp2 and merge\n",
    "prediction = pd.merge(merge, temp2, on = 'Hour',how = 'left')\n",
    "\n",
    "#Converting the ration to original scale\n",
    "prediction['Count'] = prediction['prediction'] * prediction['ratio'] * 24\n",
    "prediction['ID'] = prediction['ID_y']\n",
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "89b0a6ba6252d6ed932bbb74e91d3706b572f0c3"
   },
   "outputs": [],
   "source": [
    "submission = prediction.drop(['ID_x','ID_y','prediction','Hour','ratio'], axis =1)\n",
    "pd.DataFrame(submission, columns = ['ID','Count']).to_csv('Holt_Linear.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c194c5e1990d9b25e15ae94ab24008885985f6a9"
   },
   "source": [
    "# Predicting Timeseries: Holt Winter's Model\n",
    "\n",
    "In this method, you can change the `ExponentialSmoothing` parameters. How many season_periods gives the best predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb06270c7863e22af1cc011875f65312a0054ca5"
   },
   "outputs": [],
   "source": [
    "y_hat_avg = valid.copy()\n",
    "fit1 = ExponentialSmoothing(np.asarray(Train['Count']), seasonal_periods= 7, trend = 'add', seasonal= 'add').fit()\n",
    "y_hat_avg['Holt_Winter'] = fit1.forecast(len(valid))\n",
    "plt.figure(figsize = (16,8))\n",
    "plt.plot(Train['Count'], label = 'Train')\n",
    "plt.plot(valid['Count'], label = 'Validation')\n",
    "plt.plot(y_hat_avg.Holt_Winter, label = 'Holt Winters')\n",
    "plt.legend(loc = 'best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2da66bdd9426862bd3be720be50c55cbac5c127e"
   },
   "outputs": [],
   "source": [
    "rmse = sqrt(mean_squared_error(valid['Count'], y_hat_avg['Holt_Winter']))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85a664f8ee45b2a5ee8338885adf81665df8a25e"
   },
   "outputs": [],
   "source": [
    "predict = fit1.forecast(len(test))\n",
    "test['prediction'] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3dfe9d683e6cfa5551b35f537c24e02dcb5dbf0a"
   },
   "outputs": [],
   "source": [
    "#Merge test and test_original on day,month and year\n",
    "merge = pd.merge(test, test_original, on = ('day', 'month', 'year'), how = 'left')\n",
    "merge['Hour']= merge['Hour_y']\n",
    "merge.head()\n",
    "merge = merge.drop(['year', 'month', 'Datetime','Hour_x', 'Hour_y'], axis =1)\n",
    "\n",
    "#Predicting by merge and temp2\n",
    "prediction = pd.merge(merge, temp2 , on = 'Hour', how = 'left')\n",
    "\n",
    "#Converting the ration to original scale\n",
    "prediction['Count'] = prediction['prediction'] * prediction['ratio'] *24\n",
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ff3484ebae9aae6698e94c8655c3bb468837f12e"
   },
   "outputs": [],
   "source": [
    "prediction['ID']= prediction['ID_y']\n",
    "submission = prediction.drop(['ID_x','ID_y','day','Hour','prediction','ratio'], axis =1)\n",
    "\n",
    "pd.DataFrame(submission, columns = ['ID','Count']).to_csv('Holt winters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7aa6285a78164bc3640d4ce35d61cee89faa09fb"
   },
   "source": [
    "# Predicting Time Series: ARIMA Model\n",
    "\n",
    "Experiment with this ARIMA model by adjusting the rolling average and standard deviation windows. How do they affect the results of the Dickey-Fuller test? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f16dbe5920b5c6acf59e8658357d4504241cb8b"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def test_stationary(timeseries):\n",
    "    #Determine rolling statistics\n",
    "    rolmean = timeseries.rolling(24).mean()\n",
    "    rolstd = timeseries.rolling(24).std()\n",
    "    \n",
    "    #Plot rolling Statistics\n",
    "    orig = plt.plot(timeseries, color = \"blue\", label = \"Original\")\n",
    "    mean = plt.plot(rolmean, color = \"red\", label = \"Rolling Mean\")\n",
    "    std = plt.plot(rolstd, color = \"black\", label = \"Rolling Std\")\n",
    "    plt.legend(loc = \"best\")\n",
    "    plt.title(\"Rolling Mean and Standard Deviation\")\n",
    "    plt.show(block = False)\n",
    "    \n",
    "    #Perform Dickey Fuller test\n",
    "    print(\"Results of Dickey Fuller test: \")\n",
    "    dftest = adfuller(timeseries, autolag = 'AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index = ['Test Statistics', 'p-value', '# Lag Used', 'Number of Observations Used'])\n",
    "    \n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)' %key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5fca38363901ee82aa2d2705ab23eb4ef4dc73e6"
   },
   "outputs": [],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize']=(20,10)\n",
    "test_stationary(train_original['Count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a6adc15ab0baffe09faac7f2eab965a33862a1d0"
   },
   "source": [
    "### Remove trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8b1e0e36f11a1d6e41f7c04bc735b10e7606f46"
   },
   "outputs": [],
   "source": [
    "Train_log = np.log(Train['Count'])\n",
    "valid_log = np.log(valid['Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b385377a96eee9622ca2f2e9d62d135f8f454061"
   },
   "outputs": [],
   "source": [
    "moving_avg = Train_log.rolling(24).mean()\n",
    "plt.plot(Train_log)\n",
    "plt.plot(moving_avg, color = 'red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c20f04bcb3820d7a7c900f870bef98eea05fa6f"
   },
   "outputs": [],
   "source": [
    "train_log_moving_diff = Train_log - moving_avg\n",
    "train_log_moving_diff.dropna(inplace = True)\n",
    "test_stationary(train_log_moving_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4546b34fa6fd8c30bb7bfb285b5f217ce15a95ef"
   },
   "source": [
    "### Differencing can help to make the series stable and eliminate trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7691022b05bafb82ee7a602feff7c1a7602842ad"
   },
   "outputs": [],
   "source": [
    "train_log_diff = Train_log - Train_log.shift(1)\n",
    "test_stationary(train_log_diff.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "af98f5d4eb829b09e07e53573a411cdd7ec42997"
   },
   "source": [
    "### Removing Seasonailty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "072d280550d248010be412c5a536188e43482201"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "plt.figure(figsize = (16,10))\n",
    "decomposition = seasonal_decompose(pd.DataFrame(Train_log).Count.values, freq = 24)\n",
    "plt.style.use('default')\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "plt.subplot(411)\n",
    "plt.plot(Train_log, label = 'Original')\n",
    "plt.legend(loc = 'best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label = 'Trend')\n",
    "plt.legend(loc = 'best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal, label = 'Seasonal')\n",
    "plt.legend(loc = 'best')\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label = 'Residuals')\n",
    "plt.legend(loc = 'best')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0c8c8b03d48e528f2e10b28a755dc3846275f148"
   },
   "source": [
    "### Check stationarity of residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "367f440768793a2f2c082bd0654758a983cf8f7e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,8))\n",
    "train_log_decompose = pd.DataFrame(residual)\n",
    "train_log_decompose['date'] = Train_log.index\n",
    "train_log_decompose.set_index('date', inplace = True)\n",
    "train_log_decompose.dropna(inplace = True)\n",
    "test_stationary(train_log_decompose[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "87e2d816a34f8e19ccaad6d2170b031ffed1308f"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "lag_acf = acf(train_log_diff.dropna(), nlags = 25)\n",
    "lag_pacf = pacf(train_log_diff.dropna(), nlags = 25, method= \"ols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4d74c1ddd58bd69656225ba4be989a85f36dbf3d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(lag_acf)\n",
    "plt.axhline( y = 0, linestyle = \"--\", color = \"gray\")\n",
    "plt.axhline( y= -1.96/np.sqrt(len(train_log_diff.dropna())), linestyle = \"--\", color = \"gray\")\n",
    "plt.axhline(y = 1.96 /np.sqrt(len(train_log_diff.dropna())), linestyle = \"--\", color = \"gray\")\n",
    "plt.title(\"Autocorrelation Function\")\n",
    "plt.show()\n",
    "# PACF\n",
    "plt.figure(figsize = (15,8))\n",
    "plt.plot(lag_pacf)\n",
    "plt.axhline(y = 0, linestyle = \"--\", color = \"gray\")\n",
    "plt.axhline(y = -1.96/np.sqrt(len(train_log_diff.dropna())), linestyle = \"--\", color = \"gray\")\n",
    "plt.axhline( y = 1.96/np.sqrt(len(train_log_diff.dropna())), linestyle = \"--\", color = \"gray\")\n",
    "plt.title(\"Partial Autocorrelation Function\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2b6f8aa10b137871365390c6aaef23fd23066adc"
   },
   "source": [
    "# Predicting Timeseries: AR Model\n",
    "\n",
    "If you're unfamiliar with the ARIMA model, it might be helpful to see what parameters and arguments you can use to improve your predictions. Read up on `p,d,q`.<br> \n",
    "[https://www.statsmodels.org/dev/generated/statsmodels.tsa.arima_model.ARIMA.html](https://www.statsmodels.org/dev/generated/statsmodels.tsa.arima_model.ARIMA.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "136116404e359ae60f0190b11d7a4032f5af6070"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "plt.figure(figsize = (15,8))\n",
    "model = ARIMA(Train_log, order = (2,1,0))  #here q value is zero since it is just AR Model\n",
    "results_AR = model.fit(disp=-1)\n",
    "plt.plot(train_log_diff.dropna(), label = \"Original\")\n",
    "plt.plot(results_AR.fittedvalues, color = 'red', label = 'Predictions')\n",
    "plt.legend(loc = 'best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b674ac36018574661a2801e976340c350f0511c2"
   },
   "outputs": [],
   "source": [
    "AR_predict = results_AR.predict(start=\"2014-06-25\", end=\"2014-09-25\")\n",
    "AR_predict = AR_predict.cumsum().shift().fillna(0)\n",
    "AR_predict1 = pd.Series(np.ones(valid.shape[0])* np.log(valid['Count'])[0], index = valid.index)\n",
    "AR_predict1=AR_predict1.add(AR_predict,fill_value=0)\n",
    "AR_predict = np.exp(AR_predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4cf9fe9ba34ef3d76d515c1bce6794b84ef3dc74"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "plt.plot(valid['Count'], label = \"Validation\")\n",
    "plt.plot(AR_predict, color = \"red\", label = \"Predict\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.title('RMSE: %.4f'% (np.sqrt(np.dot(AR_predict, valid['Count']))/valid.shape[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "20326483786cc61f08b62ad98fc90e9dd208118e"
   },
   "source": [
    "# Predicting Timeseries: Moving Average Model\n",
    "\n",
    "For this model, you can modify the same parameters (p,d,q) because the base model relies on ARIMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96e5ed7e83199c7f8ddc528b1a45b459b4f75785"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "model = ARIMA(Train_log, order = (0,1,2)) # here the p value is 0 since it is moving average model\n",
    "results_MA = model.fit(disp = -1)\n",
    "plt.plot(train_log_diff.dropna(), label = \"Original\")\n",
    "plt.plot(results_MA.fittedvalues, color = \"red\", label = \"Prediction\")\n",
    "plt.legend(loc = \"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "42c1ea42d899794463764392cb763e613b6529a9"
   },
   "outputs": [],
   "source": [
    "MA_predict = results_MA.predict(start=\"2014-06-25\", end=\"2014-09-25\")\n",
    "MA_predict=MA_predict.cumsum().shift().fillna(0)\n",
    "MA_predict1=pd.Series(np.ones(valid.shape[0]) * np.log(valid['Count'])[0], index = valid.index)\n",
    "MA_predict1=MA_predict1.add(MA_predict,fill_value=0)\n",
    "MA_predict = np.exp(MA_predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b878152fffa01bff5914636a8aa66c47ab737313"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,8))\n",
    "plt.plot(valid['Count'], label = \"Valid\")\n",
    "plt.plot(MA_predict, color = 'red', label = \"Predict\")\n",
    "plt.legend(loc= 'best')\n",
    "plt.title('RMSE: %.4f'% (np.sqrt(np.dot(MA_predict, valid['Count']))/valid.shape[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "790469da0d7bb3fd1c3828eda1e63b75ff4e03aa"
   },
   "source": [
    "### Combining Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9ba2862b1027e02852e9687f819bb93e9ec0cf0"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,8))\n",
    "model = ARIMA(Train_log, order=(2, 1, 2))  \n",
    "results_ARIMA = model.fit(disp=-1)  \n",
    "plt.plot(train_log_diff.dropna(),  label='Original')\n",
    "plt.plot(results_ARIMA.fittedvalues, color='red', label='Predicted')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9252435f4d4860e79bdef6f838c0050b02462240"
   },
   "source": [
    "### Scale model to original scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f428106f716c917bfcdb19e395cabf6c55d20aec"
   },
   "outputs": [],
   "source": [
    "\n",
    "def check_prediction_diff(predict_diff, given_set):\n",
    "    predict_diff= predict_diff.cumsum().shift().fillna(0)\n",
    "    predict_base = pd.Series(np.ones(given_set.shape[0]) * np.log(given_set['Count'])[0], index = given_set.index)\n",
    "    predict_log = predict_base.add(predict_diff,fill_value=0)\n",
    "    predict = np.exp(predict_log)\n",
    "    \n",
    "    plt.plot(given_set['Count'], label = \"Given set\")\n",
    "    plt.plot(predict, color = 'red', label = \"Predict\")\n",
    "    plt.legend(loc= 'best')\n",
    "    plt.title('RMSE: %.4f'% (np.sqrt(np.dot(predict, given_set['Count']))/given_set.shape[0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "368e8110a2b29a6d0cd62a0b91382f563b751acf"
   },
   "outputs": [],
   "source": [
    "def check_prediction_log(predict_log, given_set):\n",
    "    predict = np.exp(predict_log)\n",
    "    \n",
    "    plt.plot(given_set['Count'], label = \"Given set\")\n",
    "    plt.plot(predict, color = 'red', label = \"Predict\")\n",
    "    plt.legend(loc= 'best')\n",
    "    plt.title('RMSE: %.4f'% (np.sqrt(np.dot(predict, given_set['Count']))/given_set.shape[0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b7968788888244c49b7b910fe4a875e91ef381b9"
   },
   "outputs": [],
   "source": [
    "ARIMA_predict_diff=results_ARIMA.predict(start=\"2014-06-25\", end=\"2014-09-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91a7a3fa847c7a3b239e9f73e0dfbb8f599d0700"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16,8))\n",
    "check_prediction_diff(ARIMA_predict_diff, valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bd74c9861565749513e454de2d977bd883eedace"
   },
   "source": [
    "# Predicting Timeseries: SARIMAX Model\n",
    "\n",
    "By this point, you've probably got a pretty good idea about which parameters you can modify to make improvements to your predictions. Try out what you've learned using the SARIMAX model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f56a45c3f85eebfcf4483ae0af9a4f5a2d4eeddb"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7bd1508f578f7bf63daaefd3db4dbd823f2c6422"
   },
   "outputs": [],
   "source": [
    "y_hat_avg = valid.copy()\n",
    "fit1 = sm.tsa.statespace.SARIMAX(Train.Count, order = (2,1,4), seasonal_order =(0,1,1,7)).fit()\n",
    "y_hat_avg['SARIMA'] = fit1.predict(start=\"2014-6-25\", end=\"2014-9-25\", dynamic=True)\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(Train['Count'], label = \"Train\")\n",
    "plt.plot(valid.Count, label = \"Validation\")\n",
    "plt.plot(y_hat_avg['SARIMA'], label =\"SARIMA\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.title(\"SARIMAX Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ec2369438ecf5eec22a64b0b8e2bbcefb5d0f09"
   },
   "outputs": [],
   "source": [
    "rms = sqrt(mean_squared_error(valid.Count, y_hat_avg.SARIMA))\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "50e3d0ad2675331d44df151cec2eb6ebd9d06285"
   },
   "source": [
    "### Covert to Hourly Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "854f50e8aa413157080f322357c65c585b1a4bb0"
   },
   "outputs": [],
   "source": [
    "predict = fit1.predict(start=\"2014-9-26\", end=\"2015-4-26\", dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "646970748036902d0be7479e094505b8ab1ee7f0"
   },
   "outputs": [],
   "source": [
    "test['prediction']=predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c34a8802998888583942b5303edb63b453aa972e"
   },
   "outputs": [],
   "source": [
    "#Merge test and test_original on day,month and year\n",
    "merge = pd.merge(test,test_original, on = ('day', 'month', 'year'), how = 'left')\n",
    "merge['Hour'] = merge['Hour_y']\n",
    "\n",
    "#Predicting by merging merge and temp2\n",
    "prediction = pd.merge(merge, temp2, on = 'Hour', how = 'left')\n",
    "\n",
    "#Converting the ratio to original scale\n",
    "prediction['Count'] = prediction['prediction'] * prediction['ratio'] * 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "16c3cfd3f649383ed43fbbffb667ba299da9f8dc"
   },
   "outputs": [],
   "source": [
    "prediction['ID']=prediction['ID_y']\n",
    "submission=prediction.drop(['day','Hour','ratio','prediction', 'ID_x', 'ID_y'],axis=1)\n",
    "\n",
    "# Converting the final submission to csv format\n",
    "pd.DataFrame(submission, columns=['ID','Count']).to_csv('SARIMAX.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**[Time Series With Siraj Course Home Page](https://kaggle.com/learn/time-series-with-siraj)**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos de ML para aprendizaje supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta clase vamos a estudiar los métodos más comunes de aprendizaje supervisado, tanto en problemas de clasificación como de regresión. Dichos métodos son:\n",
    "\n",
    "* kNN: Clasificación y regresión\n",
    "* Regresión lineal simple, ridge, lasso y polinomial\n",
    "* Clasificación por regresión logística\n",
    "* Máquina de vector soporte (SVM)\n",
    "* Árboles de decisión\n",
    "\n",
    "Todas estas funciones están ya implementadas en la librería scikit-learn, así que aprenderemos a usarlas, y también a controlar alguno de los hiper-parámetros de los modelos.\n",
    "\n",
    "A lo largo de toda la clase irán apareciendo conceptos básicos en el análisis de datos y Machine Learning, como son el problema del *sobreajuste (overfitting)*, las técnicas de *regularización (smoothing)* o la normalización de los datos. También abordaremos de manera práctica el problema de la selección de modelo, aunque dejaremos métodos más avanzados (grid_search) para más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importamos algunas librerías que usaremos en la práctica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Vamos a hacer un breve recorrido por los datasets que vamos a utilizar en la práctica. Algunos de ellos son sintéticos, y se han creado con el único propósito de testear algoritmos de regresión y clasificación enuna situación controlada. Otros son dataset \"de juguete\" con fines pedagógicos, pero también usaremos algunos datasets reales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 1 - Un data set sencillo para regresión lineal simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "plt.figure()\n",
    "plt.title('Datos para regresión lineal simple en una variable')\n",
    "X_R1, y_R1 = make_regression(n_samples = 100, n_features=1,\n",
    "                            n_informative=1, bias = 150.0,\n",
    "                            noise = 30, random_state=0)\n",
    "plt.scatter(X_R1, y_R1, marker= 'o', s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 2 - Dataset sintético para regresión más compleja con 7 variables predictoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset sintético para regresión más compleja\n",
    "from sklearn.datasets import make_friedman1\n",
    "plt.figure()\n",
    "plt.title('Datos para regresión lineal más compleja en una variable')\n",
    "X_F1, y_F1 = make_friedman1(n_samples = 100,\n",
    "                           n_features = 7, random_state=0)\n",
    "\n",
    "plt.scatter(X_F1[:, 2], y_F1, marker= 'o', s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 3 - Dataset sintético para clasificación binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset sintético para clasificación binaria\n",
    "from sklearn.datasets import make_classification\n",
    "from matplotlib.colors import ListedColormap\n",
    "cmap_bold = ListedColormap(['#FFFF00', '#00FF00', '#0000FF','#000000'])\n",
    "plt.figure()\n",
    "plt.title('Clasificación binaria con 2 variables predictoras')\n",
    "X_C2, y_C2 = make_classification(n_samples = 100, n_features=2,\n",
    "                                n_redundant=0, n_informative=2,\n",
    "                                n_clusters_per_class=1, flip_y = 0.1,\n",
    "                                class_sep = 0.5, random_state=0)\n",
    "plt.scatter(X_C2[:, 0], X_C2[:, 1], c=y_C2,\n",
    "           marker= 'o', s=50, cmap=cmap_bold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 4 - Problema de clasificación binaria más complejo (clases no separables linealmente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X_D2, y_D2 = make_blobs(n_samples = 100, n_features = 2, centers = 8,\n",
    "                       cluster_std = 1.3, random_state = 4)\n",
    "y_D2 = y_D2 % 2\n",
    "plt.figure()\n",
    "plt.title('Clasificación binaria con clases no separables linealmente')\n",
    "plt.scatter(X_D2[:,0], X_D2[:,1], c=y_D2,\n",
    "           marker= 'o', s=50, cmap=cmap_bold)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 5 - Cancer de mama (Winsconsin) para diagnóstico\n",
    "\n",
    "1) ID number \n",
    "2) Diagnosis (M = malignant, B = benign) \n",
    "3-32) \n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus: \n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter) \n",
    "b) texture (standard deviation of gray-scale values) \n",
    "c) perimeter \n",
    "d) area \n",
    "e) smoothness (local variation in radius lengths) \n",
    "f) compactness (perimeter^2 / area - 1.0) \n",
    "g) concavity (severity of concave portions of the contour) \n",
    "h) concave points (number of concave portions of the contour) \n",
    "i) symmetry \n",
    "j) fractal dimension (\"coastline approximation\" - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dataset de cancer de mama para clasificación binaria\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "(X_cancer, y_cancer) = load_breast_cancer(return_X_y = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 6 -  Datos de crímenes por comunidades en USA\n",
    "\n",
    "Este dataset contiene datos sobre el número de crímenes violentos per capita distribuidos por comunidades en Estados Unidos.\n",
    "Se puede consultar el [dataset completo en UCI](http://archive.ics.uci.edu/ml/datasets/communities+and+crime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset sobre distribución de crimen por comunidades\n",
    "from adspy_shared_utilities import load_crime_dataset\n",
    "(X_crime, y_crime) = load_crime_dataset()\n",
    "X_crime.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset 7 -  Frutas (Clasificación en 4 clases con 4 variables predictoras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fruits = pd.read_table('../data/fruit_data_with_colors.txt')\n",
    "\n",
    "feature_names_fruits = ['height', 'width', 'mass', 'color_score']\n",
    "X_fruits = fruits[feature_names_fruits]\n",
    "y_fruits = fruits['fruit_label']\n",
    "target_names_fruits = ['apple', 'mandarin', 'orange', 'lemon']\n",
    "\n",
    "X_fruits_2d = fruits[['height', 'width']]\n",
    "y_fruits_2d = fruits['fruit_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors\n",
    "\n",
    "Vamos a empezar por estudiar el algoritmo k-NN y en particular la dependencia de la clasificación sobre el parámetro $k$.\n",
    "En general, \n",
    "\n",
    "* valores de $k$ pequeños dan superficies de separación más rugosas. mejor predicción en train, pero posiblemente peor en test\n",
    "\n",
    "* valores de $k$ altos dan superficies de separación más suaves. Eventualmente, si $k$ es muy alto se atribuye todo a la clase mayoritaria.\n",
    "\n",
    "En cada problema particular, tendremos que averiguar cuál es el valor de $k$ que proporciona la mejor clasificación. Vamos a probar con uno de los datasets anteriores.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación con k-NN en el dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from adspy_shared_utilities import plot_two_class_knn\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_C2, y_C2,\n",
    "                                                   random_state=0)\n",
    "\n",
    "plot_two_class_knn(X_train, y_train, 1, 'uniform', X_test, y_test)\n",
    "plot_two_class_knn(X_train, y_train, 3, 'uniform', X_test, y_test)\n",
    "plot_two_class_knn(X_train, y_train, 12, 'uniform', X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos utilizar (aunque no es muy habitual) el algoritmo de k-NN para problemas de regresión. En este caso, lo que haremos será promediar el valor de las features de los $k$ próximos vecinos para obtener el valor de la variable que se quiere predecir. Como resultado, se tendrá en 1 variables una curva constante a trozos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión con k-NN\n",
    "\n",
    "Vamos a analizar cómo funciona la regresión con k-NN en los datos para la regresión simple del dataset 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_R1, y_R1, random_state = 0)\n",
    "\n",
    "knnreg = KNeighborsRegressor(n_neighbors = 5).fit(X_train, y_train)\n",
    "\n",
    "print(knnreg.predict(X_test))\n",
    "print('R-squared test score: {:.3f}'\n",
    "     .format(knnreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, subaxes = plt.subplots(1, 2, figsize=(8,4))\n",
    "X_predict_input = np.linspace(-3, 3, 50).reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_R1[0::5], y_R1[0::5], random_state = 0)\n",
    "\n",
    "for thisaxis, K in zip(subaxes, [1, 3]):\n",
    "    knnreg = KNeighborsRegressor(n_neighbors = K).fit(X_train, y_train)\n",
    "    y_predict_output = knnreg.predict(X_predict_input)\n",
    "    thisaxis.set_xlim([-2.5, 0.75])\n",
    "    thisaxis.plot(X_predict_input, y_predict_output, '^', markersize = 10,\n",
    "                 label='Predicción', alpha=0.8)\n",
    "    thisaxis.plot(X_train, y_train, 'o', label='Valor verdadero', alpha=0.8)\n",
    "    thisaxis.set_xlabel('Variable input')\n",
    "    thisaxis.set_ylabel('Variable target')\n",
    "    thisaxis.set_title('Regresión KNN (K={})'.format(K))\n",
    "    thisaxis.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complejidad del modelo de regresión como función de K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot k-NN regression on sample dataset for different values of K\n",
    "fig, subaxes = plt.subplots(5, 1, figsize=(5,20))\n",
    "X_predict_input = np.linspace(-3, 3, 500).reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_R1, y_R1,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "for thisaxis, K in zip(subaxes, [1, 3, 7, 15, 55]):\n",
    "    knnreg = KNeighborsRegressor(n_neighbors = K).fit(X_train, y_train)\n",
    "    y_predict_output = knnreg.predict(X_predict_input)\n",
    "    train_score = knnreg.score(X_train, y_train)\n",
    "    test_score = knnreg.score(X_test, y_test)\n",
    "    thisaxis.plot(X_predict_input, y_predict_output)\n",
    "    thisaxis.plot(X_train, y_train, 'o', alpha=0.9, label='Train')\n",
    "    thisaxis.plot(X_test, y_test, '^', alpha=0.9, label='Test')\n",
    "    thisaxis.set_xlabel('Variable input')\n",
    "    thisaxis.set_ylabel('Variable target')\n",
    "    thisaxis.set_title('Regresión KNN (K={})\\n\\\n",
    "Train $R^2 = {:.3f}$,  Test $R^2 = {:.3f}$'\n",
    "                      .format(K, train_score, test_score))\n",
    "    thisaxis.legend()\n",
    "    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos de regresión lineal\n",
    "\n",
    "En esta sección vamos a ver los modelos de regresión lineal:\n",
    "\n",
    "* regresión lineal simple (sin regularización)\n",
    "* regresión lineal ridge (regularización L2)\n",
    "* regresión lineal lasso (regularización L1)\n",
    "* regresión polinómica\n",
    "\n",
    "De paso, veremos como asoma el problema del *overfitting/underfitting*, y como lo podemos atajar con técnicas de regularización que impongan una penalización a la complejidad del modelo en la función de coste.\n",
    "\n",
    "También veremos como la estandarización (en nuestro caso, escalado) de los datos conducen a una mejora en la eficiencia del ajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal\n",
    "En el primer ejemplo sobre el dataset 1 de regresión simple, vemos como ajustar un modelo de LR con sklearn, utilizando la función `LinearRegression`. \n",
    "\n",
    "* El ajuste del modelo se hace (como de costubre) con el método `fit`, y toma los datos de entrenamiento.\n",
    "* Los coeficientes (pesos) de la regresión se obtienen con el método `coef_` y `intercept_`.\n",
    "* El coeficiente R2 se obtiene con el método `score` y toma como parámetros las X e y del conjunto a predecir (train o test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_R1, y_R1,\n",
    "                                                   random_state = 0)\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print('coef. del modelo lineal (w): {}'\n",
    "     .format(linreg.coef_))\n",
    "print('ordenada en el origen (b): {:.3f}'\n",
    "     .format(linreg.intercept_))\n",
    "print('métrica R2 (training): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('métrica R2 (test): {:.3f}'\n",
    "     .format(linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal: un gráfico de ejemplo\n",
    "\n",
    "Aqui vemos el típico ejemplo de regresión lineal simple enun problema con una sola variable predictora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "plt.scatter(X_R1, y_R1, marker= 'o', s=50, alpha=0.8)\n",
    "plt.plot(X_R1, linreg.coef_ * X_R1 + linreg.intercept_, 'r-')\n",
    "plt.title('Regresión lineal por mínimos cuadrados')\n",
    "plt.xlabel('Variable input (x)')\n",
    "plt.ylabel('Variable target (y)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, podemos utilizar tantas variables predictoras como queramos, utilizando la misma sintaxis.\n",
    "\n",
    "Vamos a ver por ejemplo el resultado de una regresión lineal para predecir el número de crímenes violentos per cápito usando la base de datos sobre crimen. Vemos que ahora el vector de pesos `linreg_coef_` que se obtiene como resultado del ajuste ya no es un único número, sino un array de las mismas dimensiones que el número de variables predictoras (en este caso, 88)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime,\n",
    "                                                   random_state = 0)\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print('Crime dataset')\n",
    "print('linear model intercept: {}'\n",
    "     .format(linreg.intercept_))\n",
    "print('linear model coeff:\\n{}'\n",
    "     .format(linreg.coef_))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linreg.score(X_test, y_test)))\n",
    "X_train.shape[1]==len(linreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression\n",
    "\n",
    "En la regresión ridge añadimos un término a la función de coste, que penaliza que los pesos tomen valores demasiado elevados, y por tanto favorece modelos más simples. La idea es evitar el overfitting. Para ello, en lugar de minimizar  el error cuadrático medio, vamos a minimizar la siguiente función:\n",
    "\n",
    "$$ \\sum_{i=1}^n \\left( \\hat y_i - b- \\sum_{j=1}^k w_{ij} x_j \\right)^2 + \\lambda \\sum_{j=1}^k w_j^2 =RSS +  \\alpha \\sum_{j=1}^k w_j^2 $$\n",
    "\n",
    "El parámetro $\\alpha$ es un parámetro de regularización (*smoothing parameter*) y su valor óptimo se ha de determinar por validación. Como valores extremos:\n",
    "\n",
    "* Si $\\alpha=0$ tenemos una regresión lineal simple, sin regularizar.\n",
    "* Si $\\alpha$ es muy grande, todos los pesos irán a cero, resultando en una predicción constante que sólo contiene la ordenada en el origen.\n",
    "\n",
    "Vamos a aplicar una regressión ridge a los mosmos datos de dantes, utilizando el valor de $\\alpha=20$. Para ello, en lugar de usar el método `LinearRegression` de scikit-learn, usamos la función `Ridge` (pero todo lo demás es igual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "linridge = Ridge(alpha=20.0).fit(X_train, y_train)\n",
    "\n",
    "print('Crime dataset')\n",
    "print('ridge regression linear model intercept: {}'\n",
    "     .format(linridge.intercept_))\n",
    "print('ridge regression linear model coeff:\\n{}'\n",
    "     .format(linridge.coef_))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linridge.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linridge.score(X_test, y_test)))\n",
    "print('Number of non-zero features: {}'\n",
    "     .format(np.sum(linridge.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los resultados no son muy diferentes a los de la regresión lineal. ¿Qué está pasando ?\n",
    "Al penalizar la suma de los pesos al cuadrado, no estamos teniendo en cuenta que las variables predictoras varía sobre diferentes escalas, por tanto el mismo valor de dos pesos puede tener efectos muy diferentes, y los estamos tratando a todos por igual en el término de penalización.\n",
    "\n",
    "Solución: vamos a escalar los datos input para conseguir que todos ellos tengan la misma escala. Para ello utilizaremos la función `MinMaxScaler`que normalizará el valor más alto que tome cada variable a 1 y el más bajo a -1, escalando el resto de valores en el intervalo (-1,1).\n",
    "\n",
    "**Atención:** Es muy importante aplicar el reescalado tomando sólo el valor máximo y mínimo sobre el conjunto de entrenamiento, y luego aplicar la misma transformación al conjunto de test. No podemos filtrar información del conjunto de test (en este caso, el valor mínimo y máximo de las variables) fuera de dicho conjunto pues estaríamos haciendo trampaa y obtendríamos resultados mejores de lo que serán en realidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title('Datos de la variable ' + X_train.columns[2] )\n",
    "plt.scatter(range(len(X_train)),X_train.iloc[:,2])\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.title('Datos de la variable ' + X_train.columns[2]+ ' reescalada')\n",
    "plt.scatter(range(len(X_train_scaled)),X_train_scaled[:,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression con normalización de variables\n",
    "\n",
    "Ahora volvemos a hacer una regresión ridge con el mismo valor de $\\alpha=20$, pero utilizando los datos escalados al integvalo (0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "linridge = Ridge(alpha=20.0).fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Crime dataset')\n",
    "print('ridge regression linear model intercept: {}'\n",
    "     .format(linridge.intercept_))\n",
    "print('ridge regression linear model coeff:\\n{}'\n",
    "     .format(linridge.coef_))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linridge.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linridge.score(X_test_scaled, y_test)))\n",
    "print('Number of non-zero features: {}'\n",
    "     .format(np.sum(linridge.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el valor de $R^2$ sobre el conjunto de test ha pasado de 0.494 a 0.599, simplemente normallizando los datos !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valores óptimos de $\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Regresión Ridge: efecto del parámetro de regularización alpha\\n')\n",
    "for par_alpha in [0, 1, 10, 20, 50, 100, 1000]:\n",
    "    linridge = Ridge(alpha = par_alpha).fit(X_train_scaled, y_train)\n",
    "    r2_train = linridge.score(X_train_scaled, y_train)\n",
    "    r2_test = linridge.score(X_test_scaled, y_test)\n",
    "    num_coeff_bigger = np.sum(abs(linridge.coef_) > 1.0)\n",
    "    print('Alpha = {:.2f}\\nnum abs(coeff) > 1.0: {}, \\\n",
    "r-squared training: {:.2f}, r-squared test: {:.2f}\\n'\n",
    "         .format(par_alpha, num_coeff_bigger, r2_train, r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos por qué $\\alpha$ es un parámetro de regularización: al incrementar su valor va disminuyendo la precisión del ajuste en el conjunto de entrenamiento. Sin embargo, en el conjunto de test se consiguen mejores resultados para valores de $\\alpha$ intermedios. En este caso, el valor óptimo de $\\alpha$ es de $\\alpha=20$.\n",
    "\n",
    "* Con $\\alpha=0$ ó $\\alpha=1$ estamos en un caso de *overfitting* (el modelo es demasiado complejo y no generaliza bien)\n",
    "* Con $\\alpha=1000$ estamos en un caso de *underfitting* (el modelo es demasiado simple y no ajusta bien)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regression\n",
    "\n",
    "La regresión lasso es similar en concepto a la anterior, y la única diferencia es que en el término de penalización se utilizar la norma L1 del vector de pesos en lugar de la norma euclídea L2. Es decir, la funcióna optimizar es en este caso:\n",
    "\n",
    "$$ \\sum_{i=1}^n \\left( \\hat y_i - b- \\sum_{j=1}^k w_{ij} x_j \\right)^2 + \\alpha \\sum_{j=1}^k \\left|w_j\\right| =RSS +  \\alpha \\sum_{j=1}^k \\left|w_j\\right| $$\n",
    "\n",
    "Como vamos a ver enseguida, el efecto que tiene dicha elección es que muchos de los pesos al optimizar la función tendrán un valor directamente cero (mientras que en la regresión ridge podían tomar valores pequeños, pero no nulos).\n",
    "\n",
    "Vamos a hacer una regresión lasso con $\\alpha=2.0$ sobre los datos de crimen ya normalizados al intervalo $[0,1]$.\n",
    "Para ello utilizamos la función de scikit-learn `Lasso`, y le pasamos el parámetro de regularización y fijamos un número máximo de iteraciones en el optimizador, con el parámetro opcional `max_iter=10000`. El resto de la sintaxis es común a la regresión lineal simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "linlasso = Lasso(alpha=2.0, max_iter = 10000).fit(X_train_scaled, y_train)\n",
    "\n",
    "print('Dataset 5 - Crimen')\n",
    "print('ordenada en el origen del modelo LR lasso: {}'\n",
    "     .format(linlasso.intercept_))\n",
    "print('pesos del modelo LR lasso:\\n{}'\n",
    "     .format(linlasso.coef_))\n",
    "print('Núm de variables predictoras cuyo peso es no nulo: {}'\n",
    "     .format(np.sum(linlasso.coef_ != 0)))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linlasso.score(X_train_scaled, y_train)))\n",
    "print('R-squared score (test): {:.3f}\\n'\n",
    "     .format(linlasso.score(X_test_scaled, y_test)))\n",
    "print('Variables predictoras con peso no nulo (ordenadas por valor absoluto del peso):')\n",
    "\n",
    "for e in sorted (list(zip(list(X_crime), linlasso.coef_)),\n",
    "                key = lambda e: -abs(e[1])):\n",
    "    if e[1] != 0:\n",
    "        print('\\t{}, {:.3f}'.format(e[0], e[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos varias cosas:\n",
    "    \n",
    "* El valor de $R^2$ sobre el conjunto de test es incluso mejor que los anteriores: 0.624 (lasso), 0.599 (ridge), 0.496 (LR).\n",
    "    \n",
    "* Muchos de los pesos tras la optimización toman ya valor cero, de las 88 variables sólo sobreviven 20 con peso no nulo. Esto es muy importante porque permite hacer selección de variables de manera automática: sólo se van a utilizar 20 variables de las 88 originales, resultando en un modelo más sencillo e interpretable.\n",
    "\n",
    "* Además, el modelo es **interpretable** y nos permite no sólo hacer **predicción** sino también **inferencia**.\n",
    "Es decir, podemos entender el papel que juegan las variables en la predicción, para poder así actuar sobre ellas, en lugar de ser simplemente una caja negra que emite predicciones sin ningún control ni entendimiento por nuestra parte.\n",
    "\n",
    "* Por ejemplo, nos da una idea de qué variables son más determinantes en relación con el crimen. Las cinco primeras son:\n",
    "\n",
    "    * `PctKidsBornNeverMar`, 1488.365 - Porcentaje de niños cuyos padres no están casados\n",
    "\t* `PctKids2Par`, -1188.740 - Porcentaje de niños que conviven con sus 2 padres (correlación negativa con el crimen)\n",
    "\t* `HousVacant`, 459.538 - Número de casas vacías\n",
    "\t* `PctPersDenseHous`, 339.045 - Porcentaje de personas en casas muy ocupadas (más de 1 persona por habitación)\n",
    "\t* `NumInShelters`, 264.932 - Número de personas que viven en refugios\n",
    "    \n",
    "* Por ejemplo, las variables relacionadas con la inmigración, como  `PctImmigRecent` (Porcentaje de inmigrantes que han llegado en los últimos 3 años) tienen peso cero, es decir, no tienen influencia ninguna en la relación con el crimen según este modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizando el valor de $\\alpha$ en la Regresión Lasso \n",
    "\n",
    "Vamos a hacer lo mismo que hicimos en la regresión Ridge, probando diferentes valores de $\\alpha$ para encontrar el valor óptimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Regresión Lasso: efecto del valor de alpha sobre el número de variables usadas en el modelo final\\n')\n",
    "\n",
    "for alpha in [0.5, 1, 2, 3, 5, 10, 20, 50]:\n",
    "    linlasso = Lasso(alpha, max_iter = 10000).fit(X_train_scaled, y_train)\n",
    "    r2_train = linlasso.score(X_train_scaled, y_train)\n",
    "    r2_test = linlasso.score(X_test_scaled, y_test)\n",
    "    \n",
    "    print('Alpha = {:.2f}\\n Features que sobreviven: {}, r-squared training: {:.2f}, \\\n",
    "r-squared test: {:.2f}\\n'\n",
    "         .format(alpha, np.sum(linlasso.coef_ != 0), r2_train, r2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos en este caso que la mejor predicción en el conjunto de test se obtiene con sólo 17 variables de las 88 iniciales, para un valor de $\\alpha=3$.\n",
    "\n",
    "Conforme aumenta el valor de $\\alpha$ el modelo es más sencillo, usa menos variables e inicialmente mejora la predicción en el conjunto de test. Sobre el conjunto de entrenamiento, como siempre, el efecto de la regularización hace disminuir de manera monótona la eficiencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión polinómica\n",
    "\n",
    "La regresión polinómica es un ajuste lineal, porque las variables a optimizar (los pesos) aparecen de forma lineal en la función de coste. Sin embargo, el resultado es aproximar la función output $Y$ por un polinomio en las variables regresoras $X_i$.\n",
    "\n",
    "PAra hacer una regresión polinómica, haremos simplemente una regresión lineal pero aumentaremos el número de variables regresoras, para incluir también todos sus productos hasta el orden del polinomio fijado en el ajuste. Crearemos los valores que toman todas estas variables \"nuevas\", y haremos una regresión lineal.\n",
    "\n",
    "Vamos a hacer una regresión polinómica a los datos del Dataset 2. Primero recordamos el valor de $R^2$ en la regresión simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_F1, y_F1, random_state = 0)\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "print('linear model coeff (w): {}'\n",
    "     .format(linreg.coef_))\n",
    "print('linear model intercept (b): {:.3f}'\n",
    "     .format(linreg.intercept_))\n",
    "print('R-squared score (training): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('R-squared score (test): {:.3f}'\n",
    "     .format(linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación hacemos la transformación de los datos $X_1,\\dots,X_7$, creando los valores de $X_1 X_2$, $X_1 X_3$, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_F1_poly = poly.fit_transform(X_F1)\n",
    "print(X_F1[0])\n",
    "print(X_F1_poly[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya podemos hacer una regresión lineal con los datos transformados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_F1_poly, y_F1,\n",
    "                                                   random_state = 0)\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print('(poly deg 2) coef. modelo lineal (w):\\n{}'\n",
    "     .format(linreg.coef_))\n",
    "print('(poly deg 2) ordenada en el origen (b): {:.3f}'\n",
    "     .format(linreg.intercept_))\n",
    "print('(poly deg 2) R-squared score (training): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('(poly deg 2) R-squared score (test): {:.3f}\\n'\n",
    "     .format(linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos ya que el score $R^2$ ha subido de 0.722 en la LR simple a 0.805 con la regresión polinómica de grado 2.\n",
    "\n",
    "Sin embargo, al aumentar el grado del polinomio, introducimos muchos más coeficientes y si no añadimos un término de regularización, tendremos rápidamente un problema de *overfitting*. Vamos a combinar el ajuste polinómico de grado 2 con una regularización de tipo L2 (Ridge).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_F1_poly, y_F1,\n",
    "                                                   random_state = 0)\n",
    "linreg = Ridge().fit(X_train, y_train)\n",
    "\n",
    "print('(poly deg 2) coef. modelo lineal (w):\\n{}'\n",
    "     .format(linreg.coef_))\n",
    "print('(poly deg 2) ordenada en el origen (b): {:.3f}'\n",
    "     .format(linreg.intercept_))\n",
    "print('(poly deg 2) R-squared score (training): {:.3f}'\n",
    "     .format(linreg.score(X_train, y_train)))\n",
    "print('(poly deg 2) R-squared score (test): {:.3f}\\n'\n",
    "     .format(linreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y observamos que al hacer esto ha disminuido el score $R^2$ sobre el conjunto de entrenamiento, pero ha aumentado en el conjunto de test, y ahora ambos son similares, por lo que no hay overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos lineales para tareas de Clasificación\n",
    "\n",
    "En esta sección vamos a estudiar dos modelos para tareas de clasificación:\n",
    "\n",
    "* La regresión logística (LR)\n",
    "* Las máquinas de vector soporte (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística\n",
    "\n",
    "La regresión logística (a pesar del nombre) es en realidad un método de clasificación. Consiste en aplicar una combinación lineal de las variables predictoras $z=\\sum_{j=1}^k w_j x_j + b$, y después convertir la variable $z\\in(-\\infty,\\infty)$ a un valor en $(0,1)$ a través de la función logística\n",
    "\n",
    "$$\\hat y(z)=\\frac{1}{1+{\\rm e}^{-z}}\\qquad \\hat y\\in(0,1)$$\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/600px-Logistic-curve.svg.png)\n",
    "\n",
    "Interpretaremos $\\hat y_i$ como la probabilidad de que la instancia i pertenzca a la clase 1.\n",
    "\n",
    "Por último, la función de coste computará el error cuadrático medio sobre todas las instancias, utilizando la fórmula\n",
    "$$ L(y,\\hat y)= \\frac{1}{N}\\sum_{i=1}^N (y_i-\\hat y_i)^2$$\n",
    "donde $y_i\\in\\{0,1\\}$ es la etiqueta verdadera de la i-ésima instancia, $\\hat y_i$ es la probabilidad que devuelve la fórmula anterior. El método busca los pesos $(w_1,\\dots,w_k,b)$ que minimicen la función de coste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión logística para clasificación binaria en el Dataset 7 (frutas)\n",
    "\n",
    "Vamos a hacer una regresión logística para clasificar las frutas en dos categorías: manzana (1) y no-manzana (0), usando como variables predictoras la altura (height) y la anchura (width)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from adspy_shared_utilities import (\n",
    "plot_class_regions_for_classifier_subplot)\n",
    "\n",
    "fig, subaxes = plt.subplots(1, 1, figsize=(7, 5))\n",
    "y_fruits_apple = y_fruits_2d == 1   # problema de clasificacion binaria: manzanas frente al resto\n",
    "X_train, X_test, y_train, y_test = (\n",
    "train_test_split(X_fruits_2d.as_matrix(),\n",
    "                y_fruits_apple.as_matrix(),\n",
    "                random_state = 0))\n",
    "\n",
    "clf = LogisticRegression(C=100).fit(X_train, y_train)\n",
    "plot_class_regions_for_classifier_subplot(clf, X_train, y_train, None,\n",
    "                                         None, 'Regresión logística \\\n",
    "para clasificacion binaria\\n Dataset de frutas: Manzana vs resto',\n",
    "                                         subaxes)\n",
    "\n",
    "h = 6\n",
    "w = 8\n",
    "print('Una fruta cuya altura sea {} y cuya anchura sea {}, se predice que es : {}'\n",
    "     .format(h,w, ['otra fruta', 'una manzana'][clf.predict([[h,w]])[0]]))\n",
    "\n",
    "h = 10\n",
    "w = 7\n",
    "print('Una fruta cuya altura sea {} y cuya anchura sea {}, se predice que es : {}'\n",
    "     .format(h,w, ['otra fruta', 'una manzana'][clf.predict([[h,w]])[0]]))\n",
    "subaxes.set_xlabel('altura')\n",
    "subaxes.set_ylabel('anchura')\n",
    "\n",
    "print('Precision de la clasificación por regresión logística en el conjunto de entrenamiento: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Precision de la clasificación por regresión logística en el conjunto de test: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión logística en un dataset sintético (Dataset 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from adspy_shared_utilities import (\n",
    "plot_class_regions_for_classifier_subplot)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_C2, y_C2,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "fig, subaxes = plt.subplots(1, 1, figsize=(7, 5))\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "title = 'Regresión logística, Dataset sintético  C = {:.3f}'.format(1.0)\n",
    "plot_class_regions_for_classifier_subplot(clf, X_train, y_train,\n",
    "                                         None, None, title, subaxes)\n",
    "\n",
    "print('Precision en el conjunto de entrenamiento: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Precision en el conjunto de test: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementación de la regresión logística en scikit.learn también viene con un parámetro de regularización incorporado: el parámetro C. Este parámetro $C$ juego el papel opuesto al $\\alpha$ que hemos visto antes: valores más altos de $C$ implican menor regularización.\n",
    "\n",
    "Aquí debajo tenemos una serie de experimentos. Una mez más, el valor óptimo se alcanza por validación cruzada. Este parámetro tiene más importancia cuando hay más cantidad de variables en la regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = (\n",
    "train_test_split(X_fruits_2d.as_matrix(),\n",
    "                y_fruits_apple.as_matrix(),\n",
    "                random_state=0))\n",
    "\n",
    "fig, subaxes = plt.subplots(3, 1, figsize=(5, 10))\n",
    "\n",
    "for this_C, subplot in zip([0.1, 1, 100], subaxes):\n",
    "    clf = LogisticRegression(C=this_C).fit(X_train, y_train)\n",
    "    title ='Regresión logística (manzana vs resto), C = {:.3f}'.format(this_C)\n",
    "    \n",
    "    plot_class_regions_for_classifier_subplot(clf, X_train, y_train,\n",
    "                                             X_test, y_test, title,\n",
    "                                             subplot)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicación a un dataset real\n",
    "\n",
    "Vamos a ver cómo funciona la regresión logística para un el problema de clasificación en tumores benignos o malignos en la base de datos del cáncer de mama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer, random_state = 0)\n",
    "\n",
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "print('Dataset Cáncer de mama')\n",
    "print('Precision en el conjunto de training:: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Precision en el conjunto de test: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Máquinas de Vector Soporte (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM lineales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier_subplot\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_C2, y_C2, random_state = 0)\n",
    "\n",
    "fig, subaxes = plt.subplots(1, 1, figsize=(7, 5))\n",
    "this_C = 1.0\n",
    "clf = SVC(kernel = 'linear', C=this_C).fit(X_train, y_train)\n",
    "title = 'Linear SVC, C = {:.3f}'.format(this_C)\n",
    "plot_class_regions_for_classifier_subplot(clf, X_train, y_train, None, None, title, subaxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM lineales: influencia del parámetro C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_C2, y_C2, random_state = 0)\n",
    "fig, subaxes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "for this_C, subplot in zip([0.00001, 100], subaxes):\n",
    "    clf = LinearSVC(C=this_C).fit(X_train, y_train)\n",
    "    title = 'Linear SVC, C = {:.5f}'.format(this_C)\n",
    "    plot_class_regions_for_classifier_subplot(clf, X_train, y_train,\n",
    "                                             None, None, title, subplot)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicación a un dataset real\n",
    "\n",
    "Vamos a ver cómo funciona un clasificador SVM lineal para un el problema de clasificación en tumores benignos o malignos en la base de datos del cáncer de mama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer, random_state = 0)\n",
    "\n",
    "clf = LinearSVC().fit(X_train, y_train)\n",
    "print('Base de datos - Cáncer de mama')\n",
    "print('Precision en el conjunto de training: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Precision en el conjunto de test: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación multi-clase con clasificadores lineales\n",
    "\n",
    "Si utilizamos un clasificador lineal como un SVM en un problema con $M$ clases, la sintaxis para entrenar el clasificador es igual, pero el output produce $M$ clasificaciones de cada clase respecto al resto. Para atribuir cual de las clases se le asigna a una instancia determinada, se escoge aquella clase cuyo valor sea el más alto en cada una de las clasificaciones binarias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fruits_2d, y_fruits_2d, random_state = 0)\n",
    "\n",
    "clf = LinearSVC(C=5, random_state = 67).fit(X_train, y_train)\n",
    "print('Coefficients:\\n', clf.coef_)\n",
    "print('Intercepts:\\n', clf.intercept_)\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVMs con Kernel\n",
    "\n",
    "Los SVMs con un kernel nos permiten abordar problemas de clasificación que no son linealmente separables. El truco consiste esencialmente en hacer una inmersión del problema complejo que no es separable linealmente en un espacio de dimensión más alta (por ejemplo, como hemos hecho antes en la regresión polinómica) y buscar una separación lineal con un hiperplano en dicho espacio de dimensión más alta.\n",
    "\n",
    "Al proyectar de nuevo al espacio original (de dimensión más baja), la superficie de separación se convierte en una superficie no lineal (por la no-linealidad del cambio de variables en la inmersión)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_D2, y_D2, random_state = 0)\n",
    "\n",
    "# The default SVC kernel is radial basis function (RBF)\n",
    "plot_class_regions_for_classifier(SVC().fit(X_train, y_train),\n",
    "                                 X_train, y_train, None, None,\n",
    "                                 'SVM con Kernel RBF')\n",
    "\n",
    "# Compare decision boundries with polynomial kernel, degree = 3\n",
    "plot_class_regions_for_classifier(SVC(kernel = 'poly', degree = 3)\n",
    "                                 .fit(X_train, y_train), X_train,\n",
    "                                 y_train, None, None,\n",
    "                                 'SVM con Kernel polinómico (grado 3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### SVM con Kernel RBF: influencia del parámetro gamma\n",
    "\n",
    "Sobre el Dataset 4 de clasificación compleja (no separable linealmente) vamos a probar un SVM con kernel RBF para diversos valores del parámetro gamma, que expresa la anchura de las gaussianas de cada kernel. Vemoe que valores más altos de gamma corresponden a funciónes más concentradas en cada punto, y por tanto en superficies de separación con mayor detalle y más riesgo de overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adspy_shared_utilities import plot_class_regions_for_classifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_D2, y_D2, random_state = 0)\n",
    "fig, subaxes = plt.subplots(3, 1, figsize=(4, 11))\n",
    "\n",
    "for this_gamma, subplot in zip([0.01, 1.0, 10.0], subaxes):\n",
    "    clf = SVC(kernel = 'rbf', gamma=this_gamma).fit(X_train, y_train)\n",
    "    title = 'SVM con kernel RBF, gamma = {:.2f}'.format(this_gamma)\n",
    "    plot_class_regions_for_classifier_subplot(clf, X_train, y_train,\n",
    "                                             None, None, title, subplot)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine with RBF kernel: using both C and gamma parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier_subplot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_D2, y_D2, random_state = 0)\n",
    "fig, subaxes = plt.subplots(3, 4, figsize=(15, 10), dpi=50)\n",
    "\n",
    "for this_gamma, this_axis in zip([0.01, 1, 5], subaxes):\n",
    "    \n",
    "    for this_C, subplot in zip([0.1, 1, 15, 250], this_axis):\n",
    "        title = 'gamma = {:.2f}, C = {:.2f}'.format(this_gamma, this_C)\n",
    "        clf = SVC(kernel = 'rbf', gamma = this_gamma,\n",
    "                 C = this_C).fit(X_train, y_train)\n",
    "        plot_class_regions_for_classifier_subplot(clf, X_train, y_train,\n",
    "                                                 X_test, y_test, title,\n",
    "                                                 subplot)\n",
    "        plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicación de SVMs a datos reales\n",
    "\n",
    "Su aplicamos un SVM con kernel RBF a los datos del cancer de mama, obtenemos el siguiente resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer,\n",
    "                                                   random_state = 0)\n",
    "\n",
    "clf = SVC(C=10).fit(X_train, y_train)\n",
    "print('Dataset cancer de mama (feautures no normalizadas)')\n",
    "print('Precisión del SVM con RBF-kernel en el conjunto de entrenamiento: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Precisión del SVM con RBF-kernel en el conjunto de test: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el resultado es muy pobre en el conjunto de test, y desde luego peor que el que obteníamos con un SVM lineal o con regresión logística. ¿Cuál es el problema ?\n",
    "Una vez más, el problema es que antes de aplicar la transformación con el kernel RBF, es preciso rescalar todas las variables para que la transformación las trate a todas en pie de igualdad. Vamos a repetir el cálculo, pero ahora rescalando con el método `MinMaxScaler` antes de aplicar el SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "clf = SVC(C=10).fit(X_train_scaled, y_train)\n",
    "print('Dataset cancer de mama (feautures normalizadas con MinMaxScaler)')\n",
    "print('Precisión del SVM con RBF-kernel en el conjunto de entrenamiento: {:.2f}'\n",
    "     .format(clf.score(X_train_scaled, y_train)))\n",
    "print('Precisión del SVM con RBF-kernel en el conjunto de test:  {:.2f}'\n",
    "     .format(clf.score(X_test_scaled, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya funciona mucho mejor !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre que podamos, vamos repetir la división entre el conjunto de entrenamiento y de test varias veces, para así tener una estimación más robusta de la eficiencia de nuestro método.\n",
    "\n",
    "### Ejemplo: validación cruzada con un Clasificador k-NN\n",
    "\n",
    "Vamos a ver un ejemplo de validación cruzada con un clasificador k-NN en un problema con 2 variables predictoras.\n",
    "PAra ello usaremos el método `cross_val_score` que por defecto repite la división entre conjunto de train y test 3 veces, devolviendo un resultado para cada caso. Al final haremos un promedio para tener una medida más fiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors = 5)\n",
    "X = X_fruits_2d.as_matrix()\n",
    "y = y_fruits_2d.as_matrix()\n",
    "cv_scores = cross_val_score(clf, X, y)\n",
    "\n",
    "print('Scores obtenidas por validación cruzada (3-veces):', cv_scores)\n",
    "print('Score promedio (3-veces): {:.3f}'\n",
    "     .format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curva de validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `validation_curve` permite evaluar de manera automática un modelo con diferentes valores de un parámetro por validacion cruzada con diferentes divisiones train-test. Este será uno de los pasos que tendremos que abordar cuando hagamos selección de modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "param_range = np.logspace(-3, 3, 4)\n",
    "train_scores, test_scores = validation_curve(SVC(), X, y,\n",
    "                                            param_name='gamma',\n",
    "                                            param_range=param_range, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora `train_scores` contiene los resultados para cada valor del parámetro gamma (4 valores) en cada una de las divisiones (3 veces) del conjunto train-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo mismo pasa con `test_scores`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando esta ifnormación podemos seleccionar el mejor valor de gamma viendo toda la información sobre una curva, cuya anchura expresa la desviación típica sobre os diferentes ensayos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title('Curva de validación con SVM')\n",
    "plt.xlabel('$\\gamma$ (gamma)')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "\n",
    "plt.semilogx(param_range, train_scores_mean, label='Score en training',\n",
    "            color='darkorange', lw=lw)\n",
    "\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                color='darkorange', lw=lw)\n",
    "\n",
    "plt.semilogx(param_range, test_scores_mean, label='Score en test',\n",
    "            color='navy', lw=lw)\n",
    "\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                color='navy', lw=lw)\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de este ejemplo, tomaríamos un valor de gamma igual a 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Árboles de decisión\n",
    "\n",
    "Vamos a analizr el funcionamiento de árboles de decisión para tareas de clasificación en la base de datos de Iris (3 tipos de orquídeas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from adspy_shared_utilities import plot_decision_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state = 2)\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "print('Precisión del árbol de decisión en el conjunto de entrenamiento: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Precisión del árbol de decisión en el conjunto de test: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos poner un límite superior a la profunidad del árbol (es decir, al número de niveles) para controlar el overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = DecisionTreeClassifier(max_depth = 3).fit(X_train, y_train)\n",
    "\n",
    "print('Precisión del árbol de decisión en el conjunto de entrenamiento: {:.2f}'\n",
    "     .format(clf2.score(X_train, y_train)))\n",
    "print('Precisión del árbol de decisión en el conjunto de test:  {:.2f}'\n",
    "     .format(clf2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con ayuda de la función `plot_decision_tree` podemos visualizar el árbol de decisión. Aquí estaría el árbol completo (sin podar) en la que todos los nodos finales son puros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importancia de las variables\n",
    "\n",
    "En los árboles de decisión (y como veremos más adelante, también en los Random Forest) existe una medida de la importancia de cada variable, que es proporcional al número de veces que dicha variable ha sido escogida en alguna división. Cuanto más veces se haya utilizado una variable para dividir el dataset, más discriminatoria es dicha variable, y por tanto más relevante para el proceso de clasificación.\n",
    "\n",
    "El método `feature_importances` de la clase `DecisionTreeClassifier` nos ordena las variables por importancia. En nuestro ejemplo, podemos ver que la variable más importante (i.e. más discriminatoria) es la anchura del pétalo. Por ejemplo, sólo en base a ella se clasifica perfectamente la clase *setosa* (petal_width<0.8 cm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adspy_shared_utilities import plot_feature_importances\n",
    "\n",
    "plt.figure(figsize=(10,4), dpi=80)\n",
    "plot_feature_importances(clf, iris.feature_names)\n",
    "plt.show()\n",
    "\n",
    "print('Importancia de la variable: {}'.format(clf.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Superficies de decisión\n",
    "\n",
    "Las superficies de decisión en los árboles de decisión son siempre lineas horizontales y verticales, pue estamos dividiendo en cada nodo respecto de si una variable toma valores por encima o por debajo de un valor dado.\n",
    "\n",
    "Vamos a ver un ejemplo de una superficie de decisión para un árbol podado a profundidad 4.\n",
    "\n",
    "Prueba a cambiar el valor de tree_max_depth a valores más altos o más bajos, para ver cómo cambia la superficie de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from adspy_shared_utilities import plot_class_regions_for_classifier_subplot\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state = 0)\n",
    "fig, subaxes = plt.subplots(2, 1, figsize=(6, 12))\n",
    "\n",
    "pair_list = [[0,1], [1,2]]\n",
    "tree_max_depth = 4\n",
    "\n",
    "for pair, axis in zip(pair_list, subaxes):\n",
    "    X = X_train[:, pair]\n",
    "    y = y_train\n",
    "    \n",
    "    clf = DecisionTreeClassifier(max_depth=tree_max_depth).fit(X, y)\n",
    "    title = 'Decision Tree, max_depth = {:d}'.format(tree_max_depth)\n",
    "    plot_class_regions_for_classifier_subplot(clf, X, y, None,\n",
    "                                             None, title, axis,\n",
    "                                             iris.target_names)\n",
    "    \n",
    "    axis.set_xlabel(iris.feature_names[pair[0]])\n",
    "    axis.set_ylabel(iris.feature_names[pair[1]])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "No sólo hemos conseguido clasificar bastante bien casi todos los casos (94% de acierto), sino que además en este caso el modelo es muy interpretable, y proporciona información útil para el diagnóstico. \n",
    "\n",
    "Por ejemplo, la variable más importante, que por si sola discrimina con bastante probabilidad si es un tumor maligno o benigno es `mean concave points`. Si el valor de esta variable es menor que 0.0489, entonces con probabilidad del 95% (247/260) el tumor es benigno. En cambio, si es mayor que 0.0489, con probabilidad 88% (146/166) el tumor es maligno. La variable mide el número promedio de puntos cóncavos en la superficie de las células, es decir, como de \"arrugadas\" están.\n",
    "\n",
    "El problema de los árboles de decisión es que producen mucho overfitting, y por tanto será bueno combinarlos en métodos de *ensemble*, dando lugar a los Random Forest, que estudiaremos en la próxima clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
